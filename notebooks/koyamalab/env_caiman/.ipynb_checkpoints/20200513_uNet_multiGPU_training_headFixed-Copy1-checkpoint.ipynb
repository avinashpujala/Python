{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import relevant code\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import dask\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import multi_gpu_model\n",
    "from skimage.util import montage\n",
    "import glob\n",
    "\n",
    "#--- Import my code\n",
    "codeDir = r'\\\\dm11\\koyamalab/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "# import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.SignalProcessingTools as spt\n",
    "from apCode.machineLearning.unet import model\n",
    "from apCode.behavior import FreeSwimBehavior as fsb\n",
    "# from apCode import geom\n",
    "import apCode.hdf as hdf\n",
    "from apCode import util\n",
    "from rsNeuronsProj import util as rsp\n",
    "import apCode.behavior.headFixed as hf\n",
    "\n",
    "#--- Setting seed for reproducability\n",
    "seed = 143\n",
    "np.random.seed = seed\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "#--- Auto-reload modules\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(time.ctime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Trying multi_gpu_model for the first time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_unet = r'\\\\Koyama-S2\\Data3\\Avinash\\U net'\n",
    "path_unet = glob.glob(os.path.join(dir_unet, 'trainedU_headFixed*.h5'))[-1]\n",
    "\n",
    "# unet = mlearn.loadPreTrainedUnet(path_unet)\n",
    "# unet = model.get_unet(img_height=256, img_width=256, img_channels=1)\n",
    "unet = model.get_unet_parallel(img_height=256, img_width=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Alternatively, load pre-trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_unet = r'\\\\Koyama-S2\\Data3\\Avinash\\U net'\n",
    "path_unet = glob.glob(os.path.join(dir_unet, 'trainedU_multiGPU_headFixed*.h5'))[-1]\n",
    "path_wts = glob.glob(os.path.join(dir_unet, 'best_weights_headFixed*.hdf'))[-1]\n",
    "print(path_wts)\n",
    "# unet = model.get_unet_parallel(img_height=256, img_width=256)\n",
    "# unet.load_weights(path_wts)\n",
    "unet = mlearn.loadPreTrainedUnet(path_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\U net'\n",
    "path_xls = glob.glob(os.path.join(dir_xls, 'Paths_to*Minoru*.xlsx'))[-1]\n",
    "xls_train = pd.read_excel(path_xls, sheet_name='Uncropped')\n",
    "xls_train = xls_train.loc[xls_train.exptType=='headFixed']\n",
    "\n",
    "# changePath = lambda p: r'\\\\Koyama-S2\\\\Data3' + p.split(':')[-1] if p[1]==r\":\"\n",
    "def changePath(p):\n",
    "    if p[1] == r\":\":\n",
    "        p = r'\\\\Koyama-S2\\\\Data3' + p.split(':')[-1]\n",
    "    return p\n",
    "        \n",
    "paths_imgs = list(map(changePath, np.array(xls_train.pathToImages)))\n",
    "path_masks = list(map(changePath, np.array(xls_train.pathToMasks)))\n",
    "imgDims = unet.input_shape[1:3]\n",
    "# imgs_train, masks_train = mlearn.read_training_images_and_masks(np.array(xls_train.pathToImages), \n",
    "#                                                     np.array(xls_train.pathToMasks), imgDims=imgDims)\n",
    "imgs_train, masks_train = mlearn.read_training_images_and_masks(paths_imgs, \n",
    "                                                    path_masks, imgDims=imgDims)\n",
    "masks_train = (masks_train>0).astype(int)\n",
    "print(f'Training on {imgs_train.shape[0]} imgs of dimensions {imgs_train.shape[1:]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet.evaluate(imgs_train[..., None], masks_train[..., None], batch_size=64, verbose=1)\n",
    "print(np.c_[unet.metrics_names, metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Checkpointer callback for storing best weights\n",
    "fp = os.path.join(dir_unet, f'best_weights_headFixed_{util.timestamp()}.hdf')\n",
    "checkpointer = ModelCheckpoint(filepath=fp, monitor='val_dice_coef', verbose=1,\\\n",
    "                               save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "keras_callbacks = [checkpointer]\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Augment before training\n",
    "upSample = 7 # This will expand the training set by this much\n",
    "aug_set=('rn', 'sig', 'log', 'heq', 'rot', 'rs', 'inv')\n",
    "%time imgs_aug, masks_aug, augs = mlearn.augmentImageData(imgs_train, masks_train,\\\n",
    "                                                          upsample=upSample, aug_set=aug_set)\n",
    "\n",
    "imgs_aug = mlearn.prepare_imgs_for_unet(imgs_aug, unet)\n",
    "masks_aug = mlearn.prepare_imgs_for_unet(masks_aug, unet)\n",
    "masks_aug= (masks_aug>0).astype(int)\n",
    "print(f'Augmentation: {len(imgs_train)} --> {len(imgs_aug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet.evaluate(imgs_aug, masks_aug, batch_size=64, verbose=1)\n",
    "print(np.c_[unet.metrics_names, metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 64 # Larger batch sizes are usually better, but reduce if you get an OOM error\n",
    "epochs = 350 # Number of training epochs\n",
    "initial_epoch = 249\n",
    "validation_split = 0.11 # Fraction of images from the training set to be used for validation\n",
    "\n",
    "his = unet.fit(imgs_aug, masks_aug, epochs=epochs, batch_size=batch_size,\\\n",
    "               validation_split=validation_split, callbacks=keras_callbacks, \n",
    "               verbose=0, initial_epoch=initial_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load best weights and save U net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDims = unet.input_shape[1:3]\n",
    "if isinstance(unet.loss, str):\n",
    "    lf = unet.loss\n",
    "else:\n",
    "    lf = unet.loss.__name__\n",
    "fn = f'trainedU_multiGPU_headFixed_{inputDims[0]}x{inputDims[1]}_{lf}_{util.timestamp()}.h5'\n",
    "\n",
    "path_wts = glob.glob(os.path.join(dir_unet, 'best_weights_headFixed*.hdf'))[-1]\n",
    "print(path_wts)\n",
    "unet.load_weights(path_wts)\n",
    "\n",
    "%time unet.save(os.path.join(dir_unet, fn))\n",
    "print(fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet.evaluate(imgs_aug, masks_aug, batch_size=32, verbose=1)\n",
    "print(np.c_[unet.metrics_names, metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['val_loss'], '.')\n",
    "plt.title('Loss vs epoch')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(his.history['dice_coef'])\n",
    "plt.plot(his.history['val_dice_coef'], '.')\n",
    "plt.title('Accuracy vs epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read xls with paths to data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "dir_group = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "\n",
    "file_xls = 'GCaMP volumetric imaging summary_2020-05-09.xlsx'\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "print(xls.shape)\n",
    "xls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Go through all paths, check HDF and fill missing $Ca^{2+}$ or behavior variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchPerc = (60, )\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "inds_fish = np.array(xls.FishIdx.dropna())\n",
    "pathList = np.array([xls.loc[xls.FishIdx==ind].Path.iloc[0].replace('Y:','\\\\\\\\Koyama-S2\\\\Data3') for ind in inds_fish])\n",
    "reTrackBehav = np.array(xls.reTrackBehav)\n",
    "# inds_track = np.where(reTrackBehav==1)[0]\n",
    "\n",
    "inds_track = np.arange(len(pathList))\n",
    "pathList = pathList[inds_track]\n",
    "\n",
    "print(f'{len(pathList)} paths in total')\n",
    "\n",
    "for iPath, path_ in enumerate(pathList):\n",
    "    track_behav = False\n",
    "    track_ca = False\n",
    "    reg_ca = False\n",
    "    hfp = glob.glob(os.path.join(path_, 'procData*.h5'))\n",
    "    if len(hfp)>0:\n",
    "        hfp = hfp[-1]\n",
    "        with h5py.File(hfp, mode='r') as hFile:\n",
    "            if 'behav' not in hFile:\n",
    "                track_behav = True\n",
    "#             if 'ca_raw' not in hFile:\n",
    "#                 track_ca = True\n",
    "#             if 'ca_reg' not in hFile:\n",
    "#                 reg_ca = True\n",
    "            print(f'Path # {inds_track[iPath]+1}/{len(pathList)}')\n",
    "#         if track_ca:\n",
    "#             %time hfp_ = hf.read_and_store_ca_imgs(path_)\n",
    "#         if reg_ca:\n",
    "#             %time hfp_ = hf.register_piecewise_from_hdf(hfp_, patchPerc=patchPerc)[0]\n",
    "        if track_behav:\n",
    "            %time hfp_ = hf.extractAndStoreBehaviorData_singleFish(path_, uNet=unet, batch_size=batch_size)\n",
    "    else:\n",
    "        print(f'Path # {iPath+1}/{len(pathList)}')\n",
    "#         %time hfp_ = hf.read_and_store_ca_imgs(path_)\n",
    "#         %time hfp_ = hf.register_piecewise_from_hdf(hfp_)\n",
    "        %time hfp_ = hf.extractAndStoreBehaviorData_singleFish(path_, uNet=unet, batch_size=batch_size)\n",
    "    reTrackBehav[inds_track[iPath]] = 0\n",
    "xls = xls.assign(reTrackBehav=reTrackBehav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_ in pathList:\n",
    "    hfp = glob.glob(os.path.join(path_, 'procData*.h5'))\n",
    "    reg_ca = False\n",
    "    if len(hfp)>0:\n",
    "        hfp = hfp[-1]\n",
    "        with h5py.File(hfp, mode='r') as hFile:\n",
    "            if not 'ca_reg' in hFile:\n",
    "                print(hfp)\n",
    "                reg_ca=True\n",
    "        if reg_ca:\n",
    "            hfp_ = hf.register_piecewise_from_hdf(hfp)\n",
    "    else:\n",
    "        hfp_ = hf.register_piecewise_from_hdf(hfp)   \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = pathList[18]\n",
    "print(path_)\n",
    "hfp = glob.glob(os.path.join(path_, 'procData*.h5'))[-1]\n",
    "# %time hfp_ = hf.extractAndStoreBehaviorData_singleFish(path_, uNet=unet, batch_size=64)\n",
    "with h5py.File(hfp, mode='r') as hFile:\n",
    "    print(hFile['behav'].keys())\n",
    "    ta = np.array(hFile['behav/tailAngles'])\n",
    "    stimLoc = np.array(hFile['behav/stimLoc'])\n",
    "    stimLoc = util.to_utf(stimLoc)    \n",
    "nTrls = ta.shape[0]//50\n",
    "ta_trl = np.vsplit(ta, nTrls)\n",
    "ta = np.concatenate(ta_trl, axis=1)\n",
    "trlLen = ta_trl[0].shape[1]\n",
    "print(f'{nTrls} trls  of {trlLen} length')\n",
    "%time ta_clean = hf.cleanTailAngles(ta, dt=1/500, nWaves=10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "t = np.arange(ta.shape[1])*(1/500)\n",
    "\n",
    "stimInds = (np.arange(nTrls)*(trlLen) + 500).astype(int)\n",
    "stimTimes = t[stimInds]\n",
    "inds_head = util.findStrInList('h', stimLoc)\n",
    "# plt.plot(t, ta[-1])\n",
    "plt.plot(t, ta_clean[-1], c='k', alpha=0.75)\n",
    "for ind, st in enumerate(stimTimes):\n",
    "    if ind in inds_head:\n",
    "        plt.axvline(st, ls='--', c=plt.cm.tab10(0), alpha=0.8)\n",
    "    else:\n",
    "        plt.axvline(st, ls='--', c=plt.cm.tab10(1), alpha=0.8)\n",
    "plt.xlim(0, t[-1])\n",
    "# plt.xlim(0, 50)\n",
    "print(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Look at some visually confirmed noisy trls and retrack as need be*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman import movie\n",
    "import joblib\n",
    "\n",
    "dir_ = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group\\Figs\\Trials with GMM labels'\n",
    "fn = 'noisyTrlPaths.npy'\n",
    "noisy = np.load(os.path.join(dir_, fn), allow_pickle=True)[()]\n",
    "\n",
    "dir_ = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "path_gmm = glob.glob(os.path.join(dir_, 'gmm_headFixed_*.pkl'))[-1]\n",
    "gmm_model = joblib.load(path_gmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 36\n",
    "trlDir = noisy['trlDir'][ind]\n",
    "trl = noisy['trlIdx_glob'][ind]\n",
    "print(f'Trl # {trl} \\n{trlDir}')\n",
    "imgs = volt.img.readImagesInDir(trlDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie(imgs, fr=100).play(magnification=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_prob = fsb.prob_images_with_unet(imgs, unet, batch_size=64, verbose=1)\n",
    "%time out = hf.tailAnglesFromRawImagesUsingUnet(imgs, unet, batch_size=64, verbose=1, prob_thr=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = out['tailAngles']\n",
    "ml = out['midlines']\n",
    "inds_kept = out['inds_kept_midlines']\n",
    "inds_lost = np.setdiff1d(range(ta.shape[1]), inds_kept)\n",
    "\n",
    "imgs_mid = imgs.copy()\n",
    "for ind, img in enumerate(imgs_mid):\n",
    "    if ind in inds_kept:\n",
    "        ml_= tuple(np.fliplr(ml[ind]).astype(int).T)\n",
    "        imgs_mid[ind][ml_]=0\n",
    "        \n",
    "%time ta = hf.cleanTailAngles(ta, svd=gmm_model.svd, nWaves=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "t = np.arange(ta.shape[1])/500\n",
    "plt.plot(t, ta[-1])\n",
    "plt.plot(t[inds_lost], ta[-1][inds_lost], 'o')\n",
    "plt.xlim(0, t[-1])\n",
    "plt.ylim(np.minimum(-150, ta[-1].min()), np.maximum(150, ta[-1].max()))\n",
    "# plt.xlim(0.8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDir = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group\\Figs\\Trials with GMM labels\\noisy\\after_codeAndTrack_fix_ml'\n",
    "os.makedirs(figDir, exist_ok=True)\n",
    "title = f'Trl-{trl} with GMM labels.html'\n",
    "fig = gmm_model.plot_with_labels_interact(ta, x=t, title=title)\n",
    "fig.write_html(os.path.join(figDir, f'Trl-{trl}_with GMM labels.html'))\n",
    "print(f'Trl {trl} saved at \\n{figDir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = 75\n",
    "# mov = movie(imgs*(1-out['images_prob']).astype('float32'))\n",
    "mov = movie(imgs_mid)\n",
    "# mov.play(magnification=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov.save(os.path.join(figDir, f'Trl-{trl}_tail_prob_movie_trl.avi'))\n",
    "print(trlDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir = r'\\\\Koyama-S2\\Data3\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2019-12-18\\f1'\n",
    "nImgsToCopy=10\n",
    "tRange = (1.1, 1.25)\n",
    "# inds = np.where((t>=tRange[0]) & (t<=tRange[1]))[0]\n",
    "inds = np.array([716, 717, 719, 723, 742, 743, 748, 881])-1\n",
    "\n",
    "foo = fsb.copy_images_for_training(imgs[inds], nImgsToCopy=nImgsToCopy, savePath=saveDir, \n",
    "                                   detect_motion_frames=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(imgs_aug.shape[0], size=1)[0]\n",
    "img = np.squeeze(imgs_aug[ind])\n",
    "mask = np.squeeze(masks_aug[ind])\n",
    "m = montage((img, mask), grid_shape=(1, 2), rescale_intensity=True)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(m)\n",
    "plt.title(f'Img # {ind}, aug= {augs[ind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fsb.tail_angles_from_raw_imgs_using_unet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iTrl = 3\n",
    "imgDir = r'\\\\Koyama-S2\\Data3\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2020-01-22_nefma\\f1\\002_t\\behav'\n",
    "savePath = r'\\\\Koyama-S2\\Data3\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2020-01-22_nefma\\f1'\n",
    "import apCode.FileTools as ft\n",
    "subDirs = [os.path.join(imgDir, sd) for sd in ft.subDirsInDir(imgDir)]\n",
    "sd = subDirs[iTrl]\n",
    "\n",
    "foo = fsb.copy_images_for_training(sd, nImgsToCopy=2, savePath=savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs = r'\\\\Koyama-S2\\Data3\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2020-01-19_nefma\\f1\\001_h\\behav\\Autosave0_[00-11-1c-f1-75-10]_20200119_075226_PM'\n",
    "\n",
    "\n",
    "\n",
    "# %time imgs = volt.img.readImagesInDir(path_imgs)\n",
    "\n",
    "# %time imgs_fish, imgs_prob = fsb.fish_imgs_from_raw(imgs, unet)\n",
    "\n",
    "# %time ml = hf.midlinesFromImages(imgs_fish*0)[0]\n",
    "%time ml, inds_kept = fsb.track.midlines_from_binary_imgs(imgs_fish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time kappas = fsb.track.curvaturesAlongMidline(ml)\n",
    "ta = np.cumsum(kappas, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apCode.SignalProcessingTools import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_interp = np.ones((ta.shape[0], imgs_fish.shape[0]))*np.nan\n",
    "ta_interp[:, inds_kept] = ta\n",
    "%time ta_interp = spt.interp.nanInterp2d(ta_interp, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_prob = unet.predict(fsb.prepareForUnet_1ch(imgs, sz=uShape), batch_size=64)\n",
    "imgs_prob = np.squeeze(imgs_prob)\n",
    "%time imgs_prob = volt.img.resize(imgs_prob, imgs.shape[1:], preserve_dtype=True, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = hf.fishImgsForMidline(imgs_prob, filtSize=2.5, otsuMult=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish2, imgs_prob2 = fsb.fish_imgs_from_raw(imgs, unet, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = volt.animate_images(imgs_fish[500:2000])\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani2 = volt.animate_images(imgs_fish2[500:2000])\n",
    "ani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time midlines = midlinesFromImages(imgs_fish)[0]\n",
    "%time midlines_interp = geom.interpolateCurvesND(midlines, mode='2D', N=50)\n",
    "if verbose:\n",
    "    print('Curve smoothening...')\n",
    "midlines_interp = np.asarray(compute(*[delayed(geom.smoothen_curve)(_, smooth_fixed=smooth)\\ \n",
    "                                       for _ in midlines_interp], scheduler='processes'))\n",
    "midlines_interp = geom.equalizeCurveLens(midlines_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dic_ta = hf.tailAngles_from_hdf_concatenated_by_trials(pathList)\n",
    "ta = np.concatenate(dic_ta['tailAngles'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ta_clean, _, svd = hf.cleanTailAngles(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# t = np.arange(ta_clean.shape[1])*(1/500)\n",
    "# plt.plot(t, ta[-1])\n",
    "# plt.xlim(20, 50)\n",
    "# plt.ylim(20, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Read dataframe with all relevant information (paths, etc)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_df = r'Y:\\Avinash\\Projects\\RS recruitment\\Ablations\\session_20200422-00'\n",
    "path_df = glob.glob(os.path.join(dir_df, 'dataFrame_rsNeurons_ablations_svdClean_2020*.pkl'))[-1]\n",
    "\n",
    "df = pd.read_pickle(path_df)\n",
    "dir_save = os.path.join(dir_df, f'session_{util.timestamp()}')\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Evaluate pre-training performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_all = [np.array(ta_) for ta_ in df['tailAngles']]\n",
    "ta_all = np.concatenate(ta_all, axis=1)\n",
    "%time _, _, svd = hf.cleanTailAngles(ta_all, dt=1/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctrl.shape, df_abl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Generate probability maps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prob = np.squeeze(unet_fsb.predict(imgs_rs[..., None], batch_size=6, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Make a movie to demonstrate segmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "merge_ch = 0\n",
    "fps = 50\n",
    "cropSize = (256, 256)\n",
    "iRange = (20, 300)\n",
    "save=True\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "fp = fsb.track.findFish(-imgs_rs*imgs_prob, back_img=None)\n",
    "fp_interp = spt.interp.nanInterp1d(fp)\n",
    "\n",
    "inds = np.arange(*iRange)\n",
    "imgs_rs_crop = volt.img.cropImgsAroundPoints(imgs_rs[inds], fp_interp[inds], cropSize=cropSize)\n",
    "imgs_prob_crop = volt.img.cropImgsAroundPoints(imgs_prob[inds], fp_interp[inds], cropSize=cropSize)\n",
    "\n",
    "\n",
    "imgs_prob_255 = (imgs_prob_crop*255).astype(int)\n",
    "imgs_rs_rgb = np.array([gray2rgb(_, alpha=0.5) for _ in imgs_rs_crop])\n",
    "\n",
    "imgs_rs_rgb[..., merge_ch] = (alpha*imgs_rs_rgb[..., merge_ch] + (1-alpha)*imgs_prob_255).astype(int) \n",
    "\n",
    "dir_save = os.path.join(dir_imgs, 'proc')\n",
    "if not os.path.exists(dir_save):\n",
    "    os.mkdir(dir_save)\n",
    "fname = f'Tracking movie_trl[{iTrl}]_inTrlFrames[{iRange[0]}-{iRange[1]}]_imgDims[{cropSize[0]}x{cropSize[1]}]_{util.timestamp(\"minute\")}.avi'\n",
    "savePath = os.path.join(dir_save, fname)\n",
    "\n",
    "ani =volt.animate_images(imgs_rs_rgb, fps=fps, fig_size=(15, 15), save=save, savePath=savePath)\n",
    "print(f'Movie saved at\\n{dir_save}\\nas\\n{fname}')\n",
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Copy these images for training if performance not great*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_rs[inds].shape\n",
    "inds_mov = np.arange(37, len(inds))\n",
    "np.random.shuffle(inds_mov)\n",
    "# inds_mov = inds_mov[:10]\n",
    "# savePath = os.path.join(dir_save, 'images_train_896x')\n",
    "foo = fsb.copy_images_for_training(imgs_rs[inds][inds_mov], savePath=dir_save, nImgsToCopy=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsb.copy_images_for_training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *From segmented fish images to tail curvature timeseries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = fsb.fish_imgs_from_raw(imgs_rs, unet)[0]\n",
    "%time midlines, inds_kept_midlines = fsb.track.midlines_from_binary_imgs(imgs_fish)\n",
    "kappas = fsb.track.curvaturesAlongMidline(midlines, n=50)\n",
    "tailAngles = np.cumsum(kappas, axis=0)\n",
    "ta = hf.cleanTailAngles(tailAngles)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Plot tail angles extracted from segmented fish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot tail angles\n",
    "\n",
    "from matplotlib.colors import DivergingNorm\n",
    "norm = DivergingNorm(0, vmin=-100, vmax=100)\n",
    "fh, ax = plt.subplots(2,1, figsize=(20,10), sharex=True)\n",
    "\n",
    "ax[0].imshow(ta[:, inds], aspect='auto', norm=norm, cmap='coolwarm', vmin=-100, vmax=100)\n",
    "ax[0].set_yticks([0, 24, 49])\n",
    "ax[0].set_yticklabels(['Head', 'Middle', 'Tail'])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_title('Cumulative curvature along the tail')\n",
    "\n",
    "ax[1].plot(ta[-1][inds])\n",
    "ax[1].set_xlim(0, len(inds))\n",
    "ax[1].set_xticks([0, len(inds)//2, len(inds)])\n",
    "ax[1].set_xlabel('Image frame #')\n",
    "ax[1].set_ylabel('Tail bend amplitude ($^o$)')\n",
    "ax[1].set_title('Tail tail curvature timeseries');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Try Focal Loss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Instantiate U-net with focal loss specified during compilation\n",
    "unet_fl = model.get_unet(img_width=896, img_height=896, img_channels=1, loss=model.focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Checkpointer callback for storing best weights\n",
    "fp = os.path.join(dir_unet, f'best_weights_headFixed_{util.timestamp()}.hdf')\n",
    "checkpointer = ModelCheckpoint(filepath=fp, monitor='val_dice_coef', verbose=1,\\\n",
    "                               save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "keras_callbacks = [checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Augment before training\n",
    "upSample=4\n",
    "aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot', 'rs')\n",
    "# aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot')\n",
    "%time imgs_aug, masks_aug, augs = mlearn.augmentImageData(imgs_train, masks_train,\\\n",
    "                                                          upsample=upSample, aug_set=aug_set)\n",
    "\n",
    "imgs_aug = mlearn.prepare_imgs_for_unet(imgs_aug, unet)\n",
    "masks_aug = mlearn.prepare_imgs_for_unet(masks_aug, unet)\n",
    "print(f'Augmentation: {len(imgs_train)} --> {len(imgs_aug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 6 # For 1024 x 1024 images I can't help but use batch_size=6\n",
    "epochs = 25\n",
    "validation_split = 0.1\n",
    "checkPoint = True\n",
    "\n",
    "his = unet_fl.fit(imgs_aug, masks_aug, epochs=epochs, batch_size=batch_size,\\\n",
    "                   validation_split=validation_split, callbacks=keras_callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = unet_fl.history.history\n",
    "print(his.keys())\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.style.use(('seaborn-poster','fivethirtyeight', 'seaborn-white'))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['val_dice_coef'],'.', label='validation set')\n",
    "plt.plot(his['dice_coef'], label='training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Dice coefficient', fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(his['val_loss'],'.', label ='validation set')\n",
    "plt.plot(his['loss'], label = 'training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Foal loss ($\\gamma = 2, unbalanced$)', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prob = np.squeeze(unet_fl.predict(imgs_rs[..., None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "merge_ch = 0\n",
    "fps = 50\n",
    "inds = np.arange(450, 3000)\n",
    "imgs_prob_255 = (imgs_prob*255).astype(int)\n",
    "imgs_rs_rgb = np.array([gray2rgb(_, alpha=0.5) for _ in imgs_rs])\n",
    "\n",
    "imgs_rs_rgb[..., merge_ch] = (alpha*imgs_rs_rgb[..., merge_ch] + (1-alpha)*imgs_prob_255).astype(int) \n",
    "ani =volt.animate_images(imgs_rs_rgb[inds], fps=fps, fig_size=(15, 15))\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = fsb.fish_imgs_from_raw(imgs_rs, unet_fl)[0]\n",
    "%time midlines, inds_kept_midlines = fsb.track.midlines_from_binary_imgs(imgs_fish)\n",
    "kappas = fsb.track.curvaturesAlongMidline(midlines, n=50)\n",
    "tailAngles = np.cumsum(kappas, axis=0)\n",
    "ta = hf.cleanTailAngles(tailAngles)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot tail angles\n",
    "\n",
    "from matplotlib.colors import DivergingNorm\n",
    "norm = DivergingNorm(0, vmin=-100, vmax=100)\n",
    "fh, ax = plt.subplots(2,1, figsize=(20,10), sharex=True)\n",
    "\n",
    "ax[0].imshow(ta[:, inds], aspect='auto', norm=norm, cmap='coolwarm', vmin=-100, vmax=100)\n",
    "ax[0].set_yticks([0, 24, 49])\n",
    "ax[0].set_yticklabels(['Head', 'Middle', 'Tail'])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_title('Cumulative curvature along the tail')\n",
    "\n",
    "ax[1].plot(ta[-1][inds])\n",
    "ax[1].set_xlim(0, len(inds))\n",
    "ax[1].set_xticks([0, len(inds)//2, len(inds)])\n",
    "ax[1].set_xlabel('Image frame #')\n",
    "ax[1].set_ylabel('Tail bend amplitude ($^o$)')\n",
    "ax[1].set_title('Tail tail curvature timeseries');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Free swim behavior*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
