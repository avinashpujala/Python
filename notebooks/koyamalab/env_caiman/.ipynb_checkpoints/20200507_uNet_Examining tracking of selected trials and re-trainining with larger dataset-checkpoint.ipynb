{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import relevant code\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import dask\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from skimage.util import montage\n",
    "import glob\n",
    "\n",
    "#--- Import my code\n",
    "codeDir = r'\\\\dm11\\koyamalab/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "# import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.SignalProcessingTools as spt\n",
    "from apCode.machineLearning.unet import model\n",
    "from apCode.behavior import FreeSwimBehavior as fsb\n",
    "# from apCode import geom\n",
    "import apCode.hdf as hdf\n",
    "from apCode import util\n",
    "from rsNeuronsProj import util as rsp\n",
    "import apCode.behavior.headFixed as hf\n",
    "\n",
    "#--- Setting seed for reproducability\n",
    "seed = 143\n",
    "np.random.seed = seed\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "#--- Auto-reload modules\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(time.ctime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Load a pre-trained U-net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_unet = r'\\\\Koyama-S2\\Data3\\Avinash\\U net'\n",
    "path_unet = glob.glob(os.path.join(dir_unet, 'trainedU_headFixed*.h5'))[-1]\n",
    "\n",
    "unet = mlearn.loadPreTrainedUnet(path_unet)\n",
    "# unet = model.get_unet(img_height=256, img_width=256, img_channels=1)\n",
    "\n",
    "if isinstance(unet.loss, str):\n",
    "    print(unet.loss)\n",
    "else:\n",
    "    print(unet.loss.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\U net'\n",
    "path_xls = glob.glob(os.path.join(dir_xls, 'Paths_to*Minoru*.xlsx'))[-1]\n",
    "xls_train = pd.read_excel(path_xls, sheet_name='Uncropped')\n",
    "xls_train = xls_train.loc[xls_train.exptType=='headFixed']\n",
    "print(path_xls)\n",
    "\n",
    "# changePath = lambda p: r'\\\\Koyama-S2\\\\Data3' + p.split(':')[-1] if p[1]==r\":\"\n",
    "def changePath(p):\n",
    "    if p[1] == r\":\":\n",
    "        p = r'\\\\Koyama-S2\\\\Data3' + p.split(':')[-1]\n",
    "    return p\n",
    "        \n",
    "paths_imgs = list(map(changePath, np.array(xls_train.pathToImages)))\n",
    "path_masks = list(map(changePath, np.array(xls_train.pathToMasks)))\n",
    "imgDims = unet.input_shape[1:3]\n",
    "# imgs_train, masks_train = mlearn.read_training_images_and_masks(np.array(xls_train.pathToImages), \n",
    "#                                                     np.array(xls_train.pathToMasks), imgDims=imgDims)\n",
    "imgs_train, masks_train = mlearn.read_training_images_and_masks(paths_imgs, \n",
    "                                                    path_masks, imgDims=imgDims)\n",
    "masks_train = (masks_train>0).astype(int)\n",
    "print(f'Training on {imgs_train.shape[0]} imgs of dimensions {imgs_train.shape[1:]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet.evaluate(imgs_train[..., None], masks_train[..., None], batch_size=32, verbose=1)\n",
    "print(np.c_[unet.metrics_names, metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Checkpointer callback for storing best weights\n",
    "fp = os.path.join(dir_unet, f'best_weights_headFixed_{util.timestamp()}.hdf')\n",
    "checkpointer = ModelCheckpoint(filepath=fp, monitor='val_dice_coef', verbose=1,\\\n",
    "                               save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "keras_callbacks = [checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Augment before training\n",
    "upSample = 5 # This will expand the training set by this much\n",
    "aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot', 'rs')\n",
    "%time imgs_aug, masks_aug, augs = mlearn.augmentImageData(imgs_train, masks_train,\\\n",
    "                                                          upsample=upSample, aug_set=aug_set)\n",
    "\n",
    "imgs_aug = mlearn.prepare_imgs_for_unet(imgs_aug, unet)\n",
    "masks_aug = mlearn.prepare_imgs_for_unet(masks_aug, unet)\n",
    "masks_aug= (masks_aug>0).astype(int)\n",
    "print(f'Augmentation: {len(imgs_train)} --> {len(imgs_aug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet.evaluate(imgs_aug, masks_aug, batch_size=32, verbose=1)\n",
    "print(np.c_[unet.metrics_names, metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# batch_size = 32 # Larger batch sizes are usually better, but reduce if you get an OOM error\n",
    "# epochs = 150 # Number of training epochs\n",
    "# validation_split = 0.1 # Fraction of images from the training set to be used for validation\n",
    "\n",
    "# his = unet.fit(imgs_aug, masks_aug, epochs=epochs, batch_size=batch_size,\\\n",
    "#                validation_split=validation_split, callbacks=keras_callbacks, \n",
    "#                verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load best weights and save U net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDims = unet.input_shape[1:3]\n",
    "if isinstance(unet.loss, str):\n",
    "    lf = unet.loss\n",
    "else:\n",
    "    lf = unet.loss.__name__\n",
    "fn = f'trainedU_headFixed_{inputDims[0]}x{inputDims[1]}_{lf}_{util.timestamp()}.h5'\n",
    "\n",
    "path_wts = glob.glob(os.path.join(dir_unet, 'best_weights_headFixed*.hdf'))[-1]\n",
    "unet.load_weights(path_wts)\n",
    "\n",
    "%time unet.save(os.path.join(dir_unet, fn))\n",
    "print(fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet.evaluate(imgs_aug, masks_aug, batch_size=32, verbose=1)\n",
    "print(np.c_[unet.metrics_names, metrics])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read xls with paths to data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "dir_group = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "\n",
    "file_xls = 'GCaMP volumetric imaging summary.xlsx'\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "xls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_fish = np.array(xls.FishIdx.dropna())\n",
    "pathList = np.array([xls.loc[xls.FishIdx==ind].Path.iloc[0].replace('Y:','\\\\\\\\Koyama-S2\\\\Data3') for ind in inds_fish])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create an SVD object for cleaning tail angles using tail angles from multiple fish and then save this model for future use. Later on, where more tail angles data becomes available, create a more comprehensive SVD object*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathInds = range(4)\n",
    "dic = dict(fishIdx=[], ta=[])\n",
    "for iPath, path_ in enumerate(pathList[pathInds]):\n",
    "    hfp = glob.glob(os.path.join(path_, 'procData*.h5'))[-1]\n",
    "    with h5py.File(hfp, mode='r') as hFile:\n",
    "        print(f'{iPath+1}/{len(pathInds)} \\n{hfp}')\n",
    "        ta_ = np.array(hFile['behav/tailAngles'])\n",
    "        nTrls = ta_.shape[0]//50\n",
    "        ta_trl = np.vsplit(ta_, nTrls)\n",
    "        ta_ = np.concatenate(ta_trl, axis=1)\n",
    "        fidx = np.repeat(iPath,  ta_.shape[1])\n",
    "        dic['fishIdx'].append(fidx)\n",
    "        dic['ta'].append(ta_)\n",
    "dic['fishIdx'] = np.concatenate(dic['fishIdx'], axis=0)\n",
    "dic['ta'] = np.concatenate(dic['ta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ta_clean, _, svd = hf.cleanTailAngles(dic['ta'], dt=1/500, nWaves=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "t = np.arange(ta_clean.shape[1])*(1/500)\n",
    "plt.plot(t, dic['ta'][-1], lw=1, alpha=0.5)\n",
    "plt.plot(t, ta_clean[-1], lw=1)\n",
    "plt.plot(t, -100*dic['fishIdx'], lw=1, ls='--')\n",
    "plt.xlim(0, t[-1])\n",
    "# plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathList[2].replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iPath = 0\n",
    "iTrl = 0\n",
    "path_ = pathList[iPath]\n",
    "hfp = glob.glob(os.path.join(path_, 'procData*.h5'))[-1]\n",
    "print(hfp)\n",
    "with h5py.File(hfp, mode='r') as hFile:\n",
    "    print(hFile['behav'].keys())\n",
    "    nTrls = hFile['behav']['tailAngles'].shape[0]//50\n",
    "    print(hFile['behav/tailAngles'].shape)\n",
    "    trlLen = hFile['behav/images_prob'].shape[0]//nTrls\n",
    "    print(f'{nTrls} trls of length {trlLen}')\n",
    "    trlInds = np.arange(trlLen*iTrl, trlLen*(iTrl+1))\n",
    "    imgs = np.array(hFile['behav/images_prob'][trlInds])\n",
    "    ta = np.array(hFile['behav/tailAngles'])\n",
    "ta_trl = np.array(np.vsplit(ta, ta.shape[0]//50))\n",
    "ta = np.concatenate(ta_trl, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_clean = hf.cleanTailAngles(ta)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(('seaborn-white', 'seaborn-talk', 'seaborn-ticks'))\n",
    "plt.figure(figsize=(20, 5))\n",
    "t = np.arange(ta.shape[1])*(1/500)\n",
    "# plt.plot(t, ta[-1])\n",
    "plt.plot(t, ta_clean[-1])\n",
    "# plt.xlim(0, t[-1])\n",
    "plt.xlim(110, 116)\n",
    "plt.ylim(-50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ani = volt.animate_images(imgs[0:250])\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs = r'\\\\Koyama-S2\\Data3\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2019-11-06\\session2\\f1_alx-gal4_xa316_uas-gamp6s\\002_t\\behav\\Autosave0_[00-11-1c-f1-75-10]_20191107_123723_AM'\n",
    "savePath = r'\\\\Koyama-S2\\Data3\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2019-11-06\\session2\\f1_alx-gal4_xa316_uas-gamp6s'\n",
    "foo = fsb.copy_images_for_training(path_imgs, nImgsToCopy=3, savePath=savePath)\n",
    "# a = np.arange(10)\n",
    "# import dask.array as darr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iPath, path_ in enumerate(pathList):\n",
    "    hfp = glob.glob(os.path.join(path_, 'procData*.h5'))[-1]\n",
    "    print(f'Path # {iPath+1}/{len(pathList)}')\n",
    "    %time hfp_ = hf.extractAndStoreBehaviorData_singleFish(path_, uNet=unet, hFilePath=hfp)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "iTrl=0\n",
    "hfp = glob.glob(os.path.join(pathList[1], 'procData*.h5'))[-1]\n",
    "with h5py.File(hfp, mode='r') as hFile:\n",
    "    nTrls = hFile['behav/tailAngles'].shape[0]//50\n",
    "    ta = np.array(hFile['behav/tailAngles'])\n",
    "    trlLen = ta.shape[1]\n",
    "    trlInds = np.arange(iTrl*trlLen, (iTrl+1)*trlLen)\n",
    "    imgs = hFile['behav/images_prob'][trlInds]\n",
    "ta = np.array(np.vsplit(ta, nTrls))\n",
    "ta = np.concatenate(ta, axis=1)\n",
    "print(ta.shape)\n",
    "ta_clean = hf.cleanTailAngles(ta, dt=1/500)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(('seaborn-talk', 'seaborn-white', 'seaborn-ticks'))\n",
    "plt.figure(figsize=(20, 5))\n",
    "t = np.arange(ta.shape[1])*(1/500)\n",
    "plt.plot(t, ta[-1])\n",
    "plt.plot(t, ta_clean[-1])\n",
    "plt.xlim(60, 80)\n",
    "# plt.imshow(imgs[54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iPath, path_ in enumerate(pathList):\n",
    "    track=False\n",
    "    hfp = glob.glob(os.path.join(path_, 'procData*.h5'))\n",
    "    if len(hfp)>0:\n",
    "        hfp = hfp[-1]\n",
    "        with h5py.File(hfp, mode='r') as hFile:\n",
    "            if not 'behav' in hFile:\n",
    "                track=True\n",
    "                print(f'Path # {iPath+1}/{len(pathList)}')\n",
    "        if track:\n",
    "            %time hfp_ = hf.read_and_store_ca_imgs(path_)\n",
    "            %time hfp_ = hf.extractAndStoreBehaviorData_singleFish(path_, uNet=unet)\n",
    "    else:\n",
    "        print(f'Path # {iPath+1}/{len(pathList)}')\n",
    "        %time hfp_ = hf.read_and_store_ca_imgs(path_)\n",
    "        %time hfp_ = hf.extractAndStoreBehaviorData_singleFish(path_, uNet=unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.register_piecewise_from_hdf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dic_ta = hf.tailAngles_from_hdf_concatenated_by_trials(pathList)\n",
    "ta = np.concatenate(dic_ta['tailAngles'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ta_clean, _, svd = hf.cleanTailAngles(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# t = np.arange(ta_clean.shape[1])*(1/500)\n",
    "# plt.plot(t, ta[-1])\n",
    "# plt.xlim(20, 50)\n",
    "# plt.ylim(20, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Read dataframe with all relevant information (paths, etc)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_df = r'Y:\\Avinash\\Projects\\RS recruitment\\Ablations\\session_20200422-00'\n",
    "path_df = glob.glob(os.path.join(dir_df, 'dataFrame_rsNeurons_ablations_svdClean_2020*.pkl'))[-1]\n",
    "\n",
    "df = pd.read_pickle(path_df)\n",
    "dir_save = os.path.join(dir_df, f'session_{util.timestamp()}')\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Evaluate pre-training performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_all = [np.array(ta_) for ta_ in df['tailAngles']]\n",
    "ta_all = np.concatenate(ta_all, axis=1)\n",
    "%time _, _, svd = hf.cleanTailAngles(ta_all, dt=1/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctrl.shape, df_abl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Generate probability maps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prob = np.squeeze(unet_fsb.predict(imgs_rs[..., None], batch_size=6, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Make a movie to demonstrate segmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "merge_ch = 0\n",
    "fps = 50\n",
    "cropSize = (256, 256)\n",
    "iRange = (20, 300)\n",
    "save=True\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "fp = fsb.track.findFish(-imgs_rs*imgs_prob, back_img=None)\n",
    "fp_interp = spt.interp.nanInterp1d(fp)\n",
    "\n",
    "inds = np.arange(*iRange)\n",
    "imgs_rs_crop = volt.img.cropImgsAroundPoints(imgs_rs[inds], fp_interp[inds], cropSize=cropSize)\n",
    "imgs_prob_crop = volt.img.cropImgsAroundPoints(imgs_prob[inds], fp_interp[inds], cropSize=cropSize)\n",
    "\n",
    "\n",
    "imgs_prob_255 = (imgs_prob_crop*255).astype(int)\n",
    "imgs_rs_rgb = np.array([gray2rgb(_, alpha=0.5) for _ in imgs_rs_crop])\n",
    "\n",
    "imgs_rs_rgb[..., merge_ch] = (alpha*imgs_rs_rgb[..., merge_ch] + (1-alpha)*imgs_prob_255).astype(int) \n",
    "\n",
    "dir_save = os.path.join(dir_imgs, 'proc')\n",
    "if not os.path.exists(dir_save):\n",
    "    os.mkdir(dir_save)\n",
    "fname = f'Tracking movie_trl[{iTrl}]_inTrlFrames[{iRange[0]}-{iRange[1]}]_imgDims[{cropSize[0]}x{cropSize[1]}]_{util.timestamp(\"minute\")}.avi'\n",
    "savePath = os.path.join(dir_save, fname)\n",
    "\n",
    "ani =volt.animate_images(imgs_rs_rgb, fps=fps, fig_size=(15, 15), save=save, savePath=savePath)\n",
    "print(f'Movie saved at\\n{dir_save}\\nas\\n{fname}')\n",
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Copy these images for training if performance not great*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_rs[inds].shape\n",
    "inds_mov = np.arange(37, len(inds))\n",
    "np.random.shuffle(inds_mov)\n",
    "# inds_mov = inds_mov[:10]\n",
    "# savePath = os.path.join(dir_save, 'images_train_896x')\n",
    "foo = fsb.copy_images_for_training(imgs_rs[inds][inds_mov], savePath=dir_save, nImgsToCopy=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsb.copy_images_for_training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *From segmented fish images to tail curvature timeseries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = fsb.fish_imgs_from_raw(imgs_rs, unet)[0]\n",
    "%time midlines, inds_kept_midlines = fsb.track.midlines_from_binary_imgs(imgs_fish)\n",
    "kappas = fsb.track.curvaturesAlongMidline(midlines, n=50)\n",
    "tailAngles = np.cumsum(kappas, axis=0)\n",
    "ta = hf.cleanTailAngles(tailAngles)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Plot tail angles extracted from segmented fish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot tail angles\n",
    "\n",
    "from matplotlib.colors import DivergingNorm\n",
    "norm = DivergingNorm(0, vmin=-100, vmax=100)\n",
    "fh, ax = plt.subplots(2,1, figsize=(20,10), sharex=True)\n",
    "\n",
    "ax[0].imshow(ta[:, inds], aspect='auto', norm=norm, cmap='coolwarm', vmin=-100, vmax=100)\n",
    "ax[0].set_yticks([0, 24, 49])\n",
    "ax[0].set_yticklabels(['Head', 'Middle', 'Tail'])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_title('Cumulative curvature along the tail')\n",
    "\n",
    "ax[1].plot(ta[-1][inds])\n",
    "ax[1].set_xlim(0, len(inds))\n",
    "ax[1].set_xticks([0, len(inds)//2, len(inds)])\n",
    "ax[1].set_xlabel('Image frame #')\n",
    "ax[1].set_ylabel('Tail bend amplitude ($^o$)')\n",
    "ax[1].set_title('Tail tail curvature timeseries');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Try Focal Loss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Instantiate U-net with focal loss specified during compilation\n",
    "unet_fl = model.get_unet(img_width=896, img_height=896, img_channels=1, loss=model.focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Checkpointer callback for storing best weights\n",
    "fp = os.path.join(dir_unet, f'best_weights_headFixed_{util.timestamp()}.hdf')\n",
    "checkpointer = ModelCheckpoint(filepath=fp, monitor='val_dice_coef', verbose=1,\\\n",
    "                               save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "keras_callbacks = [checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Augment before training\n",
    "upSample=4\n",
    "aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot', 'rs')\n",
    "# aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot')\n",
    "%time imgs_aug, masks_aug, augs = mlearn.augmentImageData(imgs_train, masks_train,\\\n",
    "                                                          upsample=upSample, aug_set=aug_set)\n",
    "\n",
    "imgs_aug = mlearn.prepare_imgs_for_unet(imgs_aug, unet)\n",
    "masks_aug = mlearn.prepare_imgs_for_unet(masks_aug, unet)\n",
    "print(f'Augmentation: {len(imgs_train)} --> {len(imgs_aug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 6 # For 1024 x 1024 images I can't help but use batch_size=6\n",
    "epochs = 25\n",
    "validation_split = 0.1\n",
    "checkPoint = True\n",
    "\n",
    "his = unet_fl.fit(imgs_aug, masks_aug, epochs=epochs, batch_size=batch_size,\\\n",
    "                   validation_split=validation_split, callbacks=keras_callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = unet_fl.history.history\n",
    "print(his.keys())\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.style.use(('seaborn-poster','fivethirtyeight', 'seaborn-white'))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['val_dice_coef'],'.', label='validation set')\n",
    "plt.plot(his['dice_coef'], label='training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Dice coefficient', fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(his['val_loss'],'.', label ='validation set')\n",
    "plt.plot(his['loss'], label = 'training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Foal loss ($\\gamma = 2, unbalanced$)', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prob = np.squeeze(unet_fl.predict(imgs_rs[..., None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "merge_ch = 0\n",
    "fps = 50\n",
    "inds = np.arange(450, 3000)\n",
    "imgs_prob_255 = (imgs_prob*255).astype(int)\n",
    "imgs_rs_rgb = np.array([gray2rgb(_, alpha=0.5) for _ in imgs_rs])\n",
    "\n",
    "imgs_rs_rgb[..., merge_ch] = (alpha*imgs_rs_rgb[..., merge_ch] + (1-alpha)*imgs_prob_255).astype(int) \n",
    "ani =volt.animate_images(imgs_rs_rgb[inds], fps=fps, fig_size=(15, 15))\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = fsb.fish_imgs_from_raw(imgs_rs, unet_fl)[0]\n",
    "%time midlines, inds_kept_midlines = fsb.track.midlines_from_binary_imgs(imgs_fish)\n",
    "kappas = fsb.track.curvaturesAlongMidline(midlines, n=50)\n",
    "tailAngles = np.cumsum(kappas, axis=0)\n",
    "ta = hf.cleanTailAngles(tailAngles)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot tail angles\n",
    "\n",
    "from matplotlib.colors import DivergingNorm\n",
    "norm = DivergingNorm(0, vmin=-100, vmax=100)\n",
    "fh, ax = plt.subplots(2,1, figsize=(20,10), sharex=True)\n",
    "\n",
    "ax[0].imshow(ta[:, inds], aspect='auto', norm=norm, cmap='coolwarm', vmin=-100, vmax=100)\n",
    "ax[0].set_yticks([0, 24, 49])\n",
    "ax[0].set_yticklabels(['Head', 'Middle', 'Tail'])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_title('Cumulative curvature along the tail')\n",
    "\n",
    "ax[1].plot(ta[-1][inds])\n",
    "ax[1].set_xlim(0, len(inds))\n",
    "ax[1].set_xticks([0, len(inds)//2, len(inds)])\n",
    "ax[1].set_xlabel('Image frame #')\n",
    "ax[1].set_ylabel('Tail bend amplitude ($^o$)')\n",
    "ax[1].set_title('Tail tail curvature timeseries');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Free swim behavior*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
