{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import relevant code\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import h5py\n",
    "import pandas as pd\n",
    "pd.options.display.precision=2\n",
    "from skimage.util import montage\n",
    "import glob\n",
    "import joblib\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "#--- Import my code\n",
    "codeDir = r'\\\\dm11\\koyamalab\\code\\python\\code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "from apCode.behavior import gmm as GMM\n",
    "import apCode.SignalProcessingTools as spt\n",
    "from apCode.behavior import FreeSwimBehavior as fsb\n",
    "import apCode.hdf as hdf\n",
    "from apCode import util\n",
    "from rsNeuronsProj import util as rsp\n",
    "import apCode.behavior.headFixed as hf\n",
    "\n",
    "#--- Setting seed for reproducability\n",
    "seed = 143\n",
    "np.random.seed = seed\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "#--- Auto-reload modules\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(time.ctime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read xls with paths to data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "dir_group = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "file_xls = 'GCaMP volumetric imaging summary_2020-05-09.xlsx'\n",
    "saveDir = os.path.join(dir_xls, 'Group')\n",
    "os.makedirs(saveDir, exist_ok=True)\n",
    "\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "print(f'Dataframe dimensions: {xls.shape}')\n",
    "xls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read tail angles from all the HDF files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "changePath = lambda path: path.replace(r\"Y:\", r\"\\\\Koyama-S2\\Data3\")\n",
    "pathList = np.array(list(map(changePath, xls.Path)))\n",
    "\n",
    "df = dict(fishIdx=[], path=[], trlIdx=[], tailAngles=[], stimLoc=[], sessionIdx=[])\n",
    "for iPath, path_ in enumerate(pathList):\n",
    "    hfp = glob.glob(os.path.join(path_, 'procData*.h5'))[-1]\n",
    "    with h5py.File(hfp, mode='r') as hFile:\n",
    "        if 'behav/stimLoc' in hFile:\n",
    "            print(f'{iPath+1}/{len(pathList)}')\n",
    "            ta = np.array(hFile['behav/tailAngles'])\n",
    "            nTrls = ta.shape[0]//50\n",
    "            ta_trl = np.vsplit(ta, nTrls)            \n",
    "            sl = util.to_utf(np.array(hFile['behav/stimLoc']))\n",
    "            stim = [_[-1] for _ in sl]\n",
    "            session = [int(_.split(\"_\")[0])-1 for _ in sl]\n",
    "            path_ = util.to_ascii(np.repeat(hfp, nTrls))\n",
    "            df['tailAngles'].extend(ta_trl)\n",
    "            df['fishIdx'].extend(np.repeat(iPath, nTrls))\n",
    "            df['path'].extend(path_)\n",
    "            df['trlIdx'].extend(np.arange(nTrls))\n",
    "            df['sessionIdx'].extend(session)\n",
    "            df['stimLoc'].extend(stim)\n",
    "df = pd.DataFrame(df)\n",
    "print(f'Dataframe dimensions: {df.shape}, \\ncolumns = {df.columns}') \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save dataframe with behavior info from all fish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'dataframe_headFixed_gCamp_behavior_{util.timestamp(\"day\")}.pkl'\n",
    "%time df.to_pickle(os.path.join(saveDir, fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Reload dataframe if resuming from here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = glob.glob(os.path.join(saveDir, 'dataframe_headFixed_gCamp_behavior*.pkl'))[-1]\n",
    "%time df = pd.read_pickle(path_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create a GMM object and fit to data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_percVar=0.99\n",
    "\n",
    "ta_orig = np.concatenate([np.array(_) for _ in df.tailAngles], axis=1)\n",
    "%time gmm_model = GMM.SvdGmm(pca_percVar=pca_percVar, pk_thr=5).fit(ta_orig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save the GMM object for future use; no need to save the SVD, PCA or Scaler objects separately because they are not attributes of the GMM object*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gmm, n_svd, n_pca = gmm_model.n_gmm_, gmm_model.n_svd_, gmm_model.pca.n_components_\n",
    "fn = f'gmm_headFixed_[{n_gmm}]_svd_[{n_svd}]_env_pca_[{n_pca}]_{util.timestamp(\"day\")}.pkl'\n",
    "%time path_gmm = joblib.dump(gmm_model, os.path.join(saveDir, fn))[0];\n",
    "print(path_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load the GMM model if resuming from here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gmm = glob.glob(os.path.join(saveDir, 'gmm_headFixed_*.pkl'))[-1]\n",
    "gmm_model = joblib.load(path_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Use the SVD object from the GMM object to clean tail angles* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_orig = np.concatenate([np.array(_) for _ in df.tailAngles], axis=1)\n",
    "\n",
    "print('Cleaning...')\n",
    "%time ta, _, svd = hf.cleanTailAngles(ta_orig, svd=gmm_model.svd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Make interactive plots of some example trials with GMM labels overlaid and save in specified directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trlLens = np.array([_.shape[1] for _ in df.tailAngles])\n",
    "ta_trl = np.hsplit(ta, np.cumsum(trlLens))[:-1]\n",
    "\n",
    "figDir = os.path.join(saveDir, 'Figs', 'Trials with GMM labels')\n",
    "os.makedirs(figDir, exist_ok=True)\n",
    "\n",
    "\n",
    "# ind = np.random.choice(range(len(ta_trl)), size=1)[0]\n",
    "for ind in range(len(ta_trl)):\n",
    "    t = np.arange(ta_trl[ind].shape[1])*(1/500)\n",
    "    path_ = util.to_utf([df.iloc[ind].path])[0].replace(\"\\\\\", \"/\")\n",
    "    title = f'session-{df.iloc[ind].sessionIdx}_trl-{df.iloc[ind].trlIdx}_stim-{df.iloc[ind].stimLoc}'\n",
    "    title = title + f'_{path_}'\n",
    "\n",
    "    fig = gmm_model.plot_with_labels_interact(ta_trl[ind], x=t, title=title)\n",
    "\n",
    "    fig.write_html(os.path.join(figDir, f'Trl-{ind}_with GMM labels.html'))\n",
    "    print(f'Trl {ind} saved at \\n{figDir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisyDir = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group\\Figs\\Trials with GMM labels\\noisy'\n",
    "regex = r'\\d{1,}'\n",
    "\n",
    "\n",
    "def get_behav_img_dir(df, trl):\n",
    "    path = os.path.split(df.iloc[trl].path)[0]\n",
    "    path = util.to_utf([path])[0]\n",
    "    stim = df.iloc[trl].stimLoc\n",
    "    session = df.iloc[trl].sessionIdx\n",
    "    trlIdx = df.iloc[trl].trlIdx\n",
    "#     regex = r'{}\\\\behav\\\\Autosave'.format(stim)\n",
    "    regex = r'[ht]\\\\behav\\\\Autosave'.format(stim)\n",
    "    \n",
    "    trlDirs = [out[0] for out in os.walk(path) if re.search(regex, out[0])]\n",
    "    trlDir = trlDirs[trlIdx]\n",
    "    return trlDir\n",
    "\n",
    "# Get trial indices for noisy trials from files in the noisy directory\n",
    "fnames = ft.findAndSortFilesInDir(noisyDir, ext='html')\n",
    "\n",
    "trls = np.array([int(re.findall(regex, fn)[0]) for fn in fnames])\n",
    "\n",
    "# Now find the image containing folder corresponding to trials\n",
    "trlDirs = []\n",
    "for iTrl, trl in enumerate(trls):\n",
    "    print(f'Trl {iTrl+1}/{len(trls)}')\n",
    "    trlDir = get_behav_img_dir(df, trl)\n",
    "    trlDirs.append(trlDir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = os.path.join(figDir, 'noisyTrlPaths.npy')\n",
    "foo = dict(trlIdx_glob=trls, trlDir=np.array(trlDirs))\n",
    "np.save(path_, foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.extractAndStoreBehaviorData_singleFish??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
