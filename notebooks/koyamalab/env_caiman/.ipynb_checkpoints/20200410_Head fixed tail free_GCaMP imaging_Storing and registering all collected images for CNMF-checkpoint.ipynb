{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.dataframe as dask_df\n",
    "import caiman as cm\n",
    "import h5py\n",
    "# from skimage.external import tifffile as tff\n",
    "from sklearn.decomposition import PCA\n",
    "import tifffile as tff\n",
    "import joblib\n",
    "import glob\n",
    "import re\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "bpl.output_notebook()\n",
    "\n",
    "\n",
    "codeDir = r'V:/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.behavior.FreeSwimBehavior as fsb\n",
    "import apCode.behavior.headFixed as hf\n",
    "import apCode.SignalProcessingTools as spt\n",
    "import apCode.geom as geom\n",
    "import importlib\n",
    "from apCode import util as util\n",
    "from apCode import hdf\n",
    "from apCode.imageAnalysis.spim import regress\n",
    "from apCode.behavior import gmm as my_gmm\n",
    "from apCode.machineLearning.preprocessing import Scaler\n",
    "\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 143\n",
    "random.seed = seed\n",
    "\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_xls = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "file_xls = 'GCaMP volumetric imaging summary.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read xl file\n",
    "idx_fish = 8\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "path_now = np.array(xls.loc[xls.FishIdx == idx_fish].Path)[0]\n",
    "print(path_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Open an existing HDF file or create a new one, if none exists*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_hFile = glob.glob(os.path.join(path_now, 'procData*.h5'))[-1]\n",
    "if len(path_hFile)==0:\n",
    "    path_hFile = os.path.join(path_now, f'procData_{util.timestamp()}.h5')\n",
    "    with h5py.File(path_hFileile, mode='a') as hFile:\n",
    "        pass\n",
    "print(path_hFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ca_tifs_to_hdf(fishDir, hFilePath=None, grpName='ca', regex='\\d{3}_[h/t]', verbose=True):\n",
    "    \"\"\" \n",
    "    Given the directory to data from a single fish, reads all the tif images in\n",
    "    a subdirectory 'fishir/d{3}_[h/t]/ca/' and writes them to an already existing \n",
    "    hdf file in the path or, if absent, a newly created and timestamped one.\n",
    "    The paths to the tif files can be found in hdfFile['filePaths_ca'], whereas the\n",
    "    images and all other relevant info can be found in hdfFile['/ca/']\n",
    "    Parameters\n",
    "    ----------\n",
    "    fishDir: str\n",
    "        Root directory containing all the image subdirectories\n",
    "    hFilePath: str or None\n",
    "        Full path to an existing file or if None, then the program automatically\n",
    "        looks for an HDF file in the path, and if absent, creates one with\n",
    "        the name procData_{timestamp}.h5\n",
    "    grpName: str\n",
    "        The name of the grop in the HDF file under which to store all the relevant\n",
    "        inforation.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import dask\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import h5py\n",
    "    from apCode import util\n",
    "    from apCode import hdf\n",
    "    \n",
    "    imgDirs = glob.glob(os.path.join(fishDir, '*/ca/'), recursive=True)\n",
    "    if len(imgDirs)==0:\n",
    "        print('No Ca image subdirectories found, check path')\n",
    "        return None\n",
    "    else:\n",
    "        print(f'{len(imgDirs)} Ca subdirectories found')\n",
    "    if hFilePath is None:\n",
    "        path_hFile = glob.glob(os.path.join(path_now, 'procData*.h5'))[-1]\n",
    "        if len(path_hFile)==0:\n",
    "            path_hFile = os.path.join(path_now, f'procData_{util.timestamp()}.h5')           \n",
    "    else:\n",
    "        path_hFile = hFilePath\n",
    "    for iSession, imgDir in enumerate(imgDirs):\n",
    "        print(f'Session # {iSession}, {imgDir}')\n",
    "        imgs_ca, tifInfo = volt.dask_array_from_scanimage_tifs(imgDir)\n",
    "        imgs_ca = imgs_ca - imgs_ca.mean(axis=0, keepdims=True)\n",
    "        imgs_ca = imgs_ca - imgs_ca.min() + 1\n",
    "        print('Baseline adjusting imgs_ca')\n",
    "        nImgs = len(imgs_ca)\n",
    "        filePaths = util.to_ascii(tifInfo['filePaths'])\n",
    "        print(f'{len(filePaths)} tif files in directory')\n",
    "        sessionNum = np.array([iSession]*nImgs)        \n",
    "        stimLoc = np.array(re.findall(regex, imgDir)*nImgs)\n",
    "        stimLoc = util.to_ascii(stimLoc)\n",
    "        keys = [f'filePaths_{grpName}', f'{grpName}/imgs_raw', f'{grpName}/sessionNum', f'{grpName}/stimLoc']\n",
    "        vals = [filePaths, imgs_ca, sessionNum, stimLoc]\n",
    "        with h5py.File(path_hFile, mode='a') as hFile:\n",
    "            if iSession==0:\n",
    "                if grpName in hFile:\n",
    "                    del hFile[grpName]\n",
    "                if f'filePaths_{grpName}' in hFile:\n",
    "                    del hFile[f'filePaths_{grpName}']\n",
    "            for key, val in zip(keys, vals):                \n",
    "                if key == f'{grpName}/imgs_raw':\n",
    "                    sfx = f'{util.to_utf([stimLoc[0]])[0]}'\n",
    "                    key_new =  '/' + key + f'/{sfx}'\n",
    "                    print(f'Dask array to HDF: {key_new}')\n",
    "                    val.to_hdf5(path_hFile, key_new)\n",
    "                else:\n",
    "                    hFile = hdf.createOrAppendToHdf(hFile, key, val, verbose=verbose)\n",
    "    return path_hFile\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time path_hFile = ca_tifs_to_hdf(path_now, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', n_processes=None,\\\n",
    "                                                 single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time foo = cm.load(path_hFile,  var_name_hdf5='ca/imgs_raw/001_h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_ca= glob.glob(os.path.join(path_now, '*/ca/'), recursive=True)\n",
    "dirs_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(os.path.join(dirs_ca[0], '*.tif'))\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fname_new = cm.save_memmap(fnames, is_3D=True, dview=dview, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time Yr, dims, T = cm.load_memmap(fname_new, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Yr.shape[-1]//30)*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getsize = lambda path, p: os.path.getsize(path)/(1024)**p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array([getsize(fn, 2) for fn in fnames])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue from the saved dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "startFresh = True # Reads hFile and df\n",
    "\n",
    "if (startFresh) & (('hFilePath' in locals()) | ('df' in locals())):\n",
    "    if 'hFilePath' in locals():\n",
    "        del hFilePath\n",
    "    if 'df' in locals():\n",
    "        del df\n",
    "\n",
    "#%% If stored dataframe exists in path read it\n",
    "if 'hFilePath' not in locals():\n",
    "    hFilePath = glob.glob(os.path.join(path_now, 'procData*.h5'))[-1]\n",
    "#     hFileName = ft.findAndSortFilesInDir(path_now, ext = 'h5', search_str = 'procData')[-1]\n",
    "#     hFilePath = os.path.join(path_now, hFileName)\n",
    "with h5py.File(hFilePath, mode = 'r') as hFile:\n",
    "    print(hFile.keys())\n",
    "\n",
    "if 'df' not in locals():\n",
    "    file_df = ft.findAndSortFilesInDir(path_now, ext = 'pickle', search_str = 'dataFrame')\n",
    "    if len(file_df)>0:\n",
    "        file_df = file_df[-1]\n",
    "        path_df = os.path.join(path_now, file_df)\n",
    "        print(path_df)\n",
    "        print('Reading dataframe...')\n",
    "        %time df = pd.read_pickle(path_df)       \n",
    "    else:\n",
    "        print('No dataframe found in path!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name_hdf = 'images_reg_ipca_flt_sigma-100'\n",
    "images = cm.load([hFilePath], fr=2, is3D=True, var_name_hdf5=var_name_hdf)\n",
    "images = images[:,1:]\n",
    "images -= images.min()-1\n",
    "images = images.transpose(0, 2, 3, 1)\n",
    "print(f'img dims = {images.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Try CNMF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save as memory mapped file (required for patch-based approach to CNMF)\n",
    "fname = 'mov_cnmf_3d.mmap'\n",
    "fname = os.path.join(path_now, fname)\n",
    "%time fname = images.save(fname, order='C')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname)\n",
    "images_mm = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "print(images_mm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', n_processes=None,\\\n",
    "                                                 single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Inititalize CNMF object*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% set parameters\n",
    "fr = 2\n",
    "merge_thresh = 0.85         # merging threshold, max correlation allowed\n",
    "p = 2                       # order of the autoregressive system\n",
    "# gnb = 2                     # number of global background components\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride = 1                  # amount of overlap between the patches in pixels\n",
    "K = 12                      # number of components per patch\n",
    "gSig = [2, 2, 2]            # expected half size of neurons in pixels\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 1.0              # space correlation threshold for accepting a component\n",
    "\n",
    "remove_very_bad_comps = True\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "cnm = cnmf.CNMF(n_processes, fr=fr, k=K, gSig=gSig, merge_thresh=merge_thresh, p=p,\n",
    "                rf=rf, dview=dview)\n",
    "\n",
    "%time cnm = cnm.fit(images_mm)\n",
    "nComps = cnm.estimates.A.shape[-1]\n",
    "print(f'{nComps} components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims);\n",
    "\n",
    "plt.figure(figsize=(20, 10)); \n",
    "plt.subplot(211)\n",
    "foo = cnm.estimates.A.toarray().max(axis=-1).reshape(dims, order='F')\n",
    "plt.imshow(spt.stats.saturateByPerc(foo.max(axis=-1)))\n",
    "\n",
    "# nmf_time = cnm.estimates.C\n",
    "# plt.subplot(212)\n",
    "# plt.plot(nmf_time[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "decay_time = 1.5  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 2      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.7   # accept components with space correlation threshold or higher\n",
    "cnm.params.change_params(params_dict={'fr': fr,\n",
    "                                      'decay_time': decay_time,\n",
    "                                      'min_SNR': min_SNR,\n",
    "                                      'rval_thr': rval_thr,\n",
    "                                      'use_cnn': use_cnn})\n",
    "\n",
    "%time cnm.estimates.evaluate_components(images_mm, cnm.params, dview=dview);\n",
    "print(('Keeping ' + str(len(cnm.estimates.idx_components)) +\n",
    "       ' and discarding  ' + str(len(cnm.estimates.idx_components_bad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims);\n",
    "\n",
    "plt.figure(figsize=(20, 10)); \n",
    "plt.subplot(211)\n",
    "foo = cnm.estimates.A.toarray().max(axis=-1).reshape(dims, order='F')\n",
    "plt.imshow(spt.stats.saturateByPerc(foo.max(axis=-1)))\n",
    "\n",
    "# nmf_time = cnm.estimates.C\n",
    "# plt.subplot(212)\n",
    "# plt.plot(nmf_time[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Now we re-run CNMF on whole FOV seeded with the accepted components*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnm.params.set('temporal', {'p': p})\n",
    "cnm2 = cnm.refit(images_mm, dview=dview)\n",
    "\n",
    "print(f'nComps before = {cnm.estimates.A.shape[-1]}, nComps now = {cnm2.estimates.A.shape[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnm2.estimates.A.shape[-1])\n",
    "cnm2.estimates.select_components(use_object=True)\n",
    "print(cnm2.estimates.A.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10)); \n",
    "# plt.subplot(211)\n",
    "foo = cnm2.estimates.A.toarray().max(axis=-1).reshape(dims, order='F')\n",
    "plt.imshow(spt.stats.saturateByPerc(foo.max(axis=-1), perc_up=95))\n",
    "\n",
    "# nmf_time = cnm.estimates.C\n",
    "# plt.subplot(212)\n",
    "# plt.plot(nmf_time[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_time = cnm2.estimates.C\n",
    "nmf_space = cnm2.estimates.A.toarray().reshape(*dims, -1, order='F')\n",
    "img_avg_zProj = images.mean(axis=0).max(axis=-1)\n",
    "img_avg_zProj_norm = spt.standardize(spt.stats.saturateByPerc(img_avg_zProj, perc_up=95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iComp = 28  # 28\n",
    "\n",
    "# spatial stuff\n",
    "a = spt.standardize(nmf_space[..., iComp].max(axis=-1))\n",
    "img = np.zeros(a.shape + (3,))\n",
    "img[..., 0] = a\n",
    "img[..., 2] = img_avg_zProj_norm\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.fliplr(img.transpose(1, 0, 2)))\n",
    "\n",
    "# timeseries\n",
    "ts = nmf_time[iComp]\n",
    "stimLoc = df.stimLoc\n",
    "inds_head = np.where(stimLoc=='h')[0]\n",
    "inds_tail = np.where(stimLoc=='t')[0]\n",
    "nTrls = df.shape[0]\n",
    "ts_trl = ts.reshape(nTrls,-1)\n",
    "ts_trl_head = ts_trl[inds_head]\n",
    "ts_trl_head = ts_trl_head - ts_trl_head[:, 0][:, None]\n",
    "ts_trl_tail = ts_trl[inds_tail]\n",
    "ts_trl_tail = ts_trl_tail - ts_trl_tail[:, 0][:, None]\n",
    "mu_head = ts_trl_head.mean(axis=0)\n",
    "mu_tail = ts_trl_tail.mean(axis=0)\n",
    "\n",
    "plt.subplot(122)\n",
    "# plt.figure(figsize=(20, 5))\n",
    "plt.plot(mu_head, label='Head')\n",
    "plt.plot(mu_tail, label='Tail')\n",
    "# plt.xlim(0, nmf_time.shape[1])\n",
    "plt.xlim(0, mu_head.shape[0]-1)\n",
    "plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% Extract DF/F values\n",
    "# cnm2 = cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)\n",
    "# dff = cnm2.F_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% reconstruct denoised movie\n",
    "denoised = (cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "            cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F')\n",
    "denoised = denoised.transpose(3, 0, 1, 2)\n",
    "print(denoised.shape)\n",
    "mov = cm.movie(denoised.max(axis=-1), fr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov.play(magnification=3, q_max=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Standard NMF\n",
    "mov -= mov.min()\n",
    "nmf_space, nmf_time = mov.NonnegativeMatrixFactorization(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iComp = 14\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(211)\n",
    "plt.imshow(nmf_space[iComp])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(nmf_time[iComp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3D version*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Rearrange dimensions to put txyz format\n",
    "images_txyz = np.transpose(images, (0, 2, 3, 1))[...,1:]\n",
    "images_txyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save as memory mapped file\n",
    "fn_new = cm.save_memmap([images_txyz], order='C', base_name='Yr_3d2', is_3D=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fn_new)\n",
    "Y = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cn = cm.local_correlations(Y)\n",
    "plt.imshow(Cn.max(0) if len(Cn.shape) == 3 else Cn, cmap='viridis',\n",
    "           vmin=np.percentile(Cn, 70), vmax=np.percentile(Cn, 99.9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Single patch approach for small data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "K = 20  # number of neurons expected per patch\n",
    "gSig = [2, 2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%capture\n",
    "# FIT\n",
    "images_now = np.reshape(Yr.T, [T] + list(dims), order='F')    # reshape data in Python format (T x X x Y x Z)\n",
    "cnm = cnm.fit(images_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Patch approach for larger datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "rf = 18  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "stride = 10  # amounpl.it of overlap between the patches in pixels\n",
    "K = 12  # number of neurons expected per patch\n",
    "gSig = [8, 8, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#%% RUN ALGORITHM ON PATCHES\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview,\n",
    "                rf=rf, stride=stride, only_init_patch=True)\n",
    "\n",
    "%time cnm = cnm.fit(images)\n",
    "print(('Number of components:' + str(cnm.estimates.A.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "fr = 2 # approx final rate  (after eventual downsampling )\n",
    "decay_time = 1.  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 3      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.7   # accept components with space correlation threshold or higher\n",
    "cnm.params.change_params(params_dict={'fr': fr,\n",
    "                                      'decay_time': decay_time,\n",
    "                                      'min_SNR': min_SNR,\n",
    "                                      'rval_thr': rval_thr,\n",
    "                                      'use_cnn': use_cnn});\n",
    "%time cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "print(('Keeping ' + str(len(cnm.estimates.idx_components)) +\n",
    "       ' and discarding  ' + str(len(cnm.estimates.idx_components_bad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "cnm.params.set('temporal', {'p': p})\n",
    "%time cnm2 = cnm.refit(images_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnm2.estimates.nb_view_components_3d(image_type='corr', dims=dims, Yr=Yr,\\\n",
    "                                     denoised_color='red', max_projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components_3d(image_type='max', dims=dims, Yr=Yr,\\\n",
    "                                     denoised_color='red', max_projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.estimates.nb_view_components_3d(image_type='max', dims=dims, Yr=Yr,\\\n",
    "#                                      denoised_color='red', max_projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cnm2.estimates.A.max(1).toarray()\n",
    "m = m.reshape(*images_now.shape[-3:])\n",
    "m = m.transpose(2, 0, 1)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
