{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import caiman as cm\n",
    "import h5py\n",
    "# from skimage.external import tifffile as tff\n",
    "from sklearn.decomposition import PCA\n",
    "import tifffile as tff\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "# import seaborn as sns\n",
    "\n",
    "codeDir = r'V:/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.behavior.FreeSwimBehavior as fsb\n",
    "import apCode.behavior.headFixed as hf\n",
    "import apCode.SignalProcessingTools as spt\n",
    "import apCode.geom as geom\n",
    "import importlib\n",
    "from apCode import util as util\n",
    "from apCode import hdf\n",
    "from apCode.imageAnalysis.spim import regress\n",
    "from apCode.behavior import gmm as my_gmm\n",
    "from apCode.machineLearning.preprocessing import Scaler\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 143\n",
    "random.seed = seed\n",
    "\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read the xls sheet with all the data paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_xls = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "file_xls = 'GCaMP volumetric imaging summary.xlsx'\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "xls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read xl file\n",
    "idx_fish = 9\n",
    "path_now = np.array(xls.loc[xls.FishIdx == idx_fish].Path)[0]\n",
    "print(path_now)\n",
    "if 'hFilePath' in locals():\n",
    "    del hFilePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue from the saved dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "startFresh = True # Reads hFile and df\n",
    "\n",
    "# if (startFresh) & (('hFilePath' in locals()) | ('df' in locals())):\n",
    "#     del hFilePath, df\n",
    "\n",
    "#%% If stored dataframe exists in path read it\n",
    "if 'hFilePath' not in locals():\n",
    "    hFileName = ft.findAndSortFilesInDir(path_now, ext = 'h5', search_str = 'procData')[-1]\n",
    "    hFilePath = os.path.join(path_now, hFileName)\n",
    "with h5py.File(hFilePath, mode = 'r') as hFile:\n",
    "    print(hFile.keys())\n",
    "\n",
    "if 'df' not in locals():\n",
    "    file_df = ft.findAndSortFilesInDir(path_now, ext = 'pickle', search_str = 'dataFrame')\n",
    "    if len(file_df)>0:\n",
    "        file_df = file_df[-1]\n",
    "        path_df = os.path.join(path_now, file_df)\n",
    "        print(path_df)\n",
    "        print('Reading dataframe...')\n",
    "        %time df = pd.read_pickle(path_df)       \n",
    "    else:\n",
    "        print('No dataframe found in path!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hFilePath, mode='r') as hFile:\n",
    "    print(hFile['ca_trls_reg'].shape)\n",
    "    stimLoc = util.to_utf(hFile['stimLocVec'][()])\n",
    "    print(len(stimLoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract useful info\n",
    "ta_trl = np.array([np.array(_) for _ in df.tailAngles])\n",
    "ta = np.concatenate(ta_trl,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Can I get a clearer and crisper image volume than the offset map from registration to draw ROIs on?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File(hFilePath, mode='r') as hFile:\n",
    "    ca = hFile['ca_trls_reg'][()]\n",
    "\n",
    "nTrls = ca.shape[0]\n",
    "trlLen = ca.shape[1]\n",
    "volDims = ca.shape[-3:]  \n",
    "ca = ca.reshape(-1, *volDims)\n",
    "ca = ca[:, 1:]\n",
    "ca_avg = ca.mean(axis=0)\n",
    "ca_avg = ca_avg - ca_avg.min() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save average stack for future reference\n",
    "# foo = ca_avg.copy()\n",
    "# for z in range(ca_avg.shape[0]):\n",
    "#     foo[z] = spt.stats.saturateByPerc(ca_avg[z], perc_up=99)\n",
    "# foo = spt.stats.saturateByPerc(ca_avg, perc_up=99)\n",
    "tff.imsave(os.path.join(path_now, 'averageCaImgVol.tif'), data=ca_avg.astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make simple Ca$^{2+}$ response maps to distinguish head and tail-elicited responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read ROIs\n",
    "# dir_rois= r'Y:\\Avinash\\Head-fixed tail free\\GCaMP imaging\\2020-01-11\\f1\\figs\\regression_ipca_flt_sigma-100_20200317-0507\\betas\\RoiSet.zip'\n",
    "\n",
    "dir_rois = os.path.join(path_now, 'RoiSet.zip')\n",
    "dir_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtSize = 1\n",
    "\n",
    "hFileName = ft.findAndSortFilesInDir(path_now, ext = 'h5', search_str='procData')[-1]\n",
    "hFilePath = os.path.join(path_now, hFileName)\n",
    "\n",
    "if 'images_blah' not in locals():\n",
    "    with h5py.File(hFilePath, mode = 'r') as hFile:\n",
    "#         images = np.array(hFile[f'images_reg_ipca_flt_sigma-{int(filtSize*100)}'])\n",
    "        images_trl = np.array(hFile['ca_trls_reg'])\n",
    "    images = images_trl.reshape(-1, *images_trl.shape[-3:])\n",
    "#     images = images[:, 1:]\n",
    "    \n",
    "\n",
    "# if 'df' not in locals():\n",
    "#     file_df = ft.findAndSortFilesInDir(path_now, ext = 'pickle', search_str='dataFrame')[-1]\n",
    "#     %time df = pd.read_pickle(os.path.join(path_now, file_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Some functions and reading of ROIs\n",
    "\n",
    "def strip_suffices(strList):\n",
    "    strList_new = []\n",
    "    for _ in strList:\n",
    "        a, b, c = _.split('.')\n",
    "        strList_new.append(a + '.' + b)\n",
    "    return np.array(strList_new)\n",
    "\n",
    "def consolidate_rois(rois, volDims):\n",
    "    roiNames_orig = list(rois.keys())\n",
    "    roiNames = strip_suffices(roiNames_orig)\n",
    "    roiNames_unique = np.unique(roiNames)\n",
    "    masks = []\n",
    "    for rn in roiNames_unique:\n",
    "        inds = util.findStrInList(rn, roiNames)\n",
    "        mask = np.zeros(volDims)\n",
    "        for ind in inds:\n",
    "            roi_ = rois[roiNames_orig[ind]]\n",
    "            z = roi_['position']\n",
    "            mask[z] = roi_['mask']\n",
    "        masks.append(mask)\n",
    "    return np.array(masks), roiNames_unique\n",
    "\n",
    "\n",
    "imgDims = images.shape[-2:]\n",
    "volDims = images.shape[-3:]\n",
    "\n",
    "_, rois = mlearn.readImageJRois(dir_rois, imgDims, multiLevel=False)\n",
    "masks, roiNames = consolidate_rois(rois, volDims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "def func_now(images, mask):\n",
    "    return np.apply_over_axes(np.mean, images*mask[None, ...], [1, 2, 3]).flatten()\n",
    "roi_ts = []\n",
    "for iMask, mask in enumerate(masks):\n",
    "    print(f'{iMask+1}/{masks.shape[0]}')\n",
    "    ts = func_now(images, mask)\n",
    "    roi_ts.append(ts)\n",
    "roi_ts = np.array(roi_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = util.findStrInList('R.Mauthner', roiNames)[0]\n",
    "\n",
    "nTrls = images_trl.shape[0]\n",
    "\n",
    "stimInds = np.arange(nTrls)\n",
    "plt.style.use(('fivethirtyeight', 'seaborn-paper'))\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(roi_ts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = False\n",
    "\n",
    "stimLoc = np.array([sl[-1] for sl in stimLoc])\n",
    "stimLoc_unique = np.unique(stimLoc)\n",
    "if len(stimLoc_unique)==1:\n",
    "    n = len(stimLoc)//2\n",
    "    stimLoc[-n:] = np.setdiff1d(['h', 't'], stimLoc_unique)\n",
    "\n",
    "\n",
    "nTrls = images_trl.shape[0]\n",
    "# nTrls = df.shape[0]\n",
    "roi_ts_trls = roi_ts.reshape(roi_ts.shape[0], nTrls, -1)\n",
    "roi_ts_trls -= roi_ts_trls[...,1][...,None]\n",
    "if 'stimLoc' not in locals():\n",
    "    stimLoc = np.array(df.stimLoc)\n",
    "trls_head = np.where(stimLoc=='h')[0]\n",
    "trls_tail = np.where(stimLoc=='t')[0]\n",
    "\n",
    "roi_ts_head = roi_ts_trls[:, trls_head]\n",
    "roi_ts_tail = roi_ts_trls[:, trls_tail]\n",
    "\n",
    "mu_head = roi_ts_head.mean(axis=1)\n",
    "sem_head = roi_ts_head.std(axis=1)/np.sqrt(mu_head.shape[0])\n",
    "mu_tail = roi_ts_tail.mean(axis=1)\n",
    "sem_tail = roi_ts_tail.std(axis=1)/np.sqrt(mu_tail.shape[0])\n",
    "\n",
    "if scale:\n",
    "    ind_m = util.findStrInList('R.Mauthner', roiNames)[0]\n",
    "    h = mu_head[ind]\n",
    "    t = mu_tail[ind]\n",
    "    sf = t.max()/h.max()\n",
    "    print(f'Scaling factor = {sf}')\n",
    "    roi_ts_head = roi_ts_head*sf\n",
    "    mu_head = roi_ts_head.mean(axis=1)\n",
    "    sem_head = roi_ts_head.std(axis=1)/np.sqrt(mu_head.shape[0])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20, 20*nRows/nCols))\n",
    "nCols = 3\n",
    "nRows = int(np.ceil(len(roiNames)/nCols))\n",
    "fh, ax = plt.subplots(nrows=nRows, ncols=nCols, sharex=True, figsize=(20, 20*nRows/nCols))\n",
    "ax = ax.flatten()\n",
    "fh.tight_layout()\n",
    "\n",
    "t = np.arange(mu_head.shape[1])*(1/2)\n",
    "for iRoi, roi_ in enumerate(mu_head):\n",
    "#     ax[iRoi].plot(mu_head[iRoi], c=plt.cm.tab10(0), label='Head')\n",
    "    ax[iRoi].fill_between(t, mu_head[iRoi]-sem_head[iRoi], mu_head[iRoi]+sem_head[iRoi],\n",
    "                          color=plt.cm.tab10(0), alpha=0.5, label='Head')\n",
    "    ax[iRoi].fill_between(t, mu_tail[iRoi]-sem_tail[iRoi], mu_tail[iRoi]+sem_tail[iRoi],\n",
    "                          color=plt.cm.tab10(1), alpha=0.5, label='Tail')\n",
    "#     ax[iRoi].plot(t,mu_tail[iRoi], c=plt.cm.tab10(1), label='Tail')\n",
    "    ax[iRoi].set_yticks([])\n",
    "    ax[iRoi].set_title(r'${}$'.format(roiNames[iRoi]), fontsize=20)\n",
    "    if iRoi==0:\n",
    "        ax[iRoi].legend(loc='best', fontsize=20)\n",
    "fh.suptitle('Average Ca$^{2+}$ response for escape trials_Head vs tail stimulation\\n R = ipi, L = contra', \\\n",
    "           fontsize=24);\n",
    "fh.subplots_adjust(top=0.955, hspace=0.12)\n",
    "\n",
    "dir_figs = os.path.join(path_now, 'figs')\n",
    "if not os.path.exists(dir_figs):\n",
    "    os.mkdir(dir_figs)\n",
    "fn = f'Fig-{util.timestamp(\"minute\")}_Trial-averaged Ca2+ responses_head and tail trials'\n",
    "# fh.savefig(os.path.join(dir_figs, fn + '.pdf'), dpi='figure', format='pdf')\n",
    "# fh.savefig(os.path.join(dir_figs, fn + '.png'), dpi='figure', format='png')\n",
    "print(f'Saved at \\n{dir_figs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save a dataframe of roi timeseries that can be quickly accessed later\n",
    "df_roi = dict(roiName=[], stimLoc=[], ca=[])\n",
    "for iRoi, roi_ in enumerate(roiNames):\n",
    "    for iStim, sl in enumerate(stimLoc):\n",
    "        df_roi['roiName'].append(roi_)\n",
    "        df_roi['stimLoc'].append(sl)\n",
    "        df_roi['ca'].append(roi_ts_trls[iRoi, iStim])\n",
    "print('Converting from dict to dataframe...')\n",
    "df_roi = pd.DataFrame(df_roi)\n",
    "\n",
    "print('Saving dataframe...')\n",
    "%time df_roi.to_pickle(os.path.join(path_now, f'roi_ts_dataframe_{util.timestamp()}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_now.replace(\"\\\\\", \"/\"), f'fishIdx = {idx_fish}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path_ = glob.glob(os.path.join(path_now, 'roi_ts_*.pkl'))[0]\n",
    "df_roi = pd.read_pickle(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roiNames = np.array(df_roi.roiName)\n",
    "# inds = util.findStrInList('R.MiDi', roiNames)\n",
    "inds = np.where(roiNames=='R.MiD2')\n",
    "roiNames[inds] = 'R.MiD2i'\n",
    "df_roi = df_roi.assign(roiName=roiNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Saving dataframe...')\n",
    "%time df_roi.to_pickle(os.path.join(path_now, f'roi_ts_dataframe_{util.timestamp()}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrls = ca_trl.shape[0]\n",
    "roi_ts_trls = roi_ts.reshape(roi_ts.shape[0], nTrls, -1)\n",
    "roi_ts_trls -= roi_ts_trls[...,0][...,None]\n",
    "trls_head = np.where(stimLoc=='h')[0]\n",
    "trls_tail = np.where(stimLoc=='t')[0]\n",
    "\n",
    "roi_ts_head = roi_ts_trls[:, trls_head]\n",
    "roi_ts_tail = roi_ts_trls[:, trls_tail]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "mu_head = roi_ts_head.mean(axis=1)\n",
    "sigma_head = roi_ts_head.std(axis=1)\n",
    "mu_tail = roi_ts_tail.mean(axis=1)\n",
    "sigma_tail = roi_ts_tail.std(axis=1)\n",
    "\n",
    "\n",
    "yOff = 2*np.max(mu_head)*np.arange(roi_ts_trls.shape[0])[:, None]\n",
    "# yOff = util.yOffMat(mu_head)*2\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot((mu_head-yOff).T);\n",
    "plt.plot((mu_head+sigma_head-yOff).T, c='k', alpha=0.25);\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot((mu_tail-yOff).T);\n",
    "plt.plot((mu_tail+sigma_tail-yOff).T, c='k', alpha=0.25);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% NMF in ROI-masked areas\n",
    "masks_zProj = masks==1\n",
    "masks_zPproj = masks.max(axis=1).max(axis=0)\n",
    "images_zProj = images.mean(axis=1)\n",
    "images_zProj_mask = masks_zPproj[None, ...]*images_zProj\n",
    "mov = cm.movie(images_zProj_mask)\n",
    "mov -= mov.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nmf_space, nmf_time = mov.NonnegativeMatrixFactorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iComp = 10\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.imshow(spt.standardize(nmf_space[iComp]), vmax=0.5)\n",
    "plt.subplot(212)\n",
    "plt.plot(nmf_time.T[iComp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Try CNMF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bpl\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *CNMF* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *If data is small enough use a single patch approach*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_now = images[:,1:]\n",
    "images_ser = images_now.reshape(images_now.shape[0], -1)\n",
    "nTrls = df.shape[0]\n",
    "trlLen = images_now.shape[0]/nTrls\n",
    "\n",
    "# %time regObj = regress(X_reg[:,-2:], images_ser, n_jobs=-1, fit_intercept=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(X_reg.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_now = images[:,1:]\n",
    "imgs_proj = images_now.mean(axis=1)\n",
    "mov = cm.movie(imgs_proj, fr=2)\n",
    "# mov -= mov.min()\n",
    "df_ca, baseline = mov.computeDFF()\n",
    "# df = mov.bilateral_blur_2D()\n",
    "# df = mov.copy()\n",
    "df_ca = np.array(df_ca)\n",
    "df_ca -= df_ca.min()\n",
    "print(df_ca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save as memory mapped file\n",
    "fn_new = cm.save_memmap([df_ca], order='C', base_name='Yr9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fn_new)\n",
    "images_now = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "print(images_now.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', n_processes=None,\\\n",
    "                                                 single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Inititalize CNMF object*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import bokeh.plotting as bpl\n",
    "# bpl.output_notebook()\n",
    "\n",
    "# set parameters\n",
    "fr = 2\n",
    "# K = 20  # number of neurons expected per patch\n",
    "# gSig = [2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.9  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system\n",
    "\n",
    "gnb = 2                     # number of global background components\n",
    "rf = 45                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 10             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [20, 20]               # expected half size of neurons in pixels\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 1.0              # space correlation threshold for accepting a component\n",
    "\n",
    "remove_very_bad_comps = False\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "cnm = cnmf.CNMF(n_processes, fr=fr, k=K, gSig=gSig, merge_thresh=merge_thresh, p=p, rf=rf, dview=dview,\\\n",
    "                min_SNR=min_SNR, rval_thr=rval_thr, remove_very_bad_comps=remove_very_bad_comps)\n",
    "\n",
    "%time cnm = cnm.fit(images_now)\n",
    "nComps = cnm.estimates.A.shape[-1]\n",
    "print(f'{nComps} components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(images_now.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours(img=Cn, thr=0.8);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 23\n",
    "plt.figure(figsize=(10, 5)); \n",
    "plt.subplot(211)\n",
    "plt.imshow(np.reshape(cnm.estimates.A[:,i-1].toarray(), dims, order='F'))\n",
    "\n",
    "nmf_time = cnm.estimates.C\n",
    "plt.subplot(212)\n",
    "plt.plot(nmf_time[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "%time cnm2 = cnm.refit(images_now, dview=dview)\n",
    "print(f'{cnm2.estimates.A.shape[-1]} components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "# cnm2.estimates.evaluate_components(images_now, cnm2.params, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.plot_contours(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% Extract DF/F values\n",
    "# cnm2 = cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)\n",
    "# dff = cnm2.F_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iSlc = 16\n",
    "slc = images[:,iSlc,...]\n",
    "plt.imshow(slc.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Standard NMF\n",
    "mov -= mov.min()\n",
    "nmf_space, nmf_time = mov.NonnegativeMatrixFactorization(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iComp = 14\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(211)\n",
    "plt.imshow(nmf_space[iComp])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(nmf_time[iComp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3D version*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Rearrange dimensions to put txyz format\n",
    "images_txyz = np.transpose(images, (0, 2, 3, 1))[...,1:]\n",
    "images_txyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save as memory mapped file\n",
    "fn_new = cm.save_memmap([images_txyz], order='C', base_name='Yr_3d2', is_3D=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fn_new)\n",
    "Y = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cn = cm.local_correlations(Y)\n",
    "plt.imshow(Cn.max(0) if len(Cn.shape) == 3 else Cn, cmap='viridis',\n",
    "           vmin=np.percentile(Cn, 70), vmax=np.percentile(Cn, 99.9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Single patch approach for small data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "K = 20  # number of neurons expected per patch\n",
    "gSig = [2, 2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%capture\n",
    "# FIT\n",
    "images_now = np.reshape(Yr.T, [T] + list(dims), order='F')    # reshape data in Python format (T x X x Y x Z)\n",
    "cnm = cnm.fit(images_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Patch approach for larger datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "rf = 18  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "stride = 10  # amounpl.it of overlap between the patches in pixels\n",
    "K = 12  # number of neurons expected per patch\n",
    "gSig = [8, 8, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#%% RUN ALGORITHM ON PATCHES\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview,\n",
    "                rf=rf, stride=stride, only_init_patch=True)\n",
    "\n",
    "%time cnm = cnm.fit(images)\n",
    "print(('Number of components:' + str(cnm.estimates.A.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "fr = 2 # approx final rate  (after eventual downsampling )\n",
    "decay_time = 1.  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 3      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.7   # accept components with space correlation threshold or higher\n",
    "cnm.params.change_params(params_dict={'fr': fr,\n",
    "                                      'decay_time': decay_time,\n",
    "                                      'min_SNR': min_SNR,\n",
    "                                      'rval_thr': rval_thr,\n",
    "                                      'use_cnn': use_cnn});\n",
    "%time cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "print(('Keeping ' + str(len(cnm.estimates.idx_components)) +\n",
    "       ' and discarding  ' + str(len(cnm.estimates.idx_components_bad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "cnm.params.set('temporal', {'p': p})\n",
    "%time cnm2 = cnm.refit(images_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnm2.estimates.nb_view_components_3d(image_type='corr', dims=dims, Yr=Yr,\\\n",
    "                                     denoised_color='red', max_projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components_3d(image_type='max', dims=dims, Yr=Yr,\\\n",
    "                                     denoised_color='red', max_projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.estimates.nb_view_components_3d(image_type='max', dims=dims, Yr=Yr,\\\n",
    "#                                      denoised_color='red', max_projection=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cnm2.estimates.A.max(1).toarray()\n",
    "m = m.reshape(*images_now.shape[-3:])\n",
    "m = m.transpose(2, 0, 1)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
