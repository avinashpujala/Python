{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import caiman as cm\n",
    "import h5py\n",
    "# from skimage.external import tifffile as tff\n",
    "from sklearn.decomposition import PCA\n",
    "import tifffile as tff\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "codeDir = r'V:/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.behavior.FreeSwimBehavior as fsb\n",
    "import apCode.behavior.headFixed as hf\n",
    "import apCode.SignalProcessingTools as spt\n",
    "import apCode.geom as geom\n",
    "import importlib\n",
    "from apCode import util as util\n",
    "from apCode import hdf\n",
    "from apCode.imageAnalysis.spim import regress\n",
    "from apCode.behavior import gmm as my_gmm\n",
    "from apCode.machineLearning.preprocessing import Scaler\n",
    "import rsNeuronsProj.util as rsp\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 143\n",
    "random.seed = seed\n",
    "\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read the xls sheet with all the data paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_xls = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "file_xls = 'GCaMP volumetric imaging summary.xlsx'\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "xls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Behavior variability*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% A function for extracting behavior and stim location from paths and putting in dataframe\n",
    "def get_behav_from_path(path, fishLen=50):\n",
    "    path_hFile = glob.glob(os.path.join(path, 'procData*.h5'))\n",
    "    if len(path_hFile)>0:\n",
    "        path_hFile = path_hFile[-1]\n",
    "    else:\n",
    "        print(f'No HDF file in path:\\t {path}')\n",
    "        return None\n",
    "    with h5py.File(path_hFile, mode='r') as hFile:\n",
    "        if 'behav' in hFile:\n",
    "            grp = hFile['behav']\n",
    "            if ('tailAngles' in grp) & ('stimLoc' in grp):\n",
    "                ta = np.array(grp['tailAngles'])\n",
    "                nTrls = ta.shape[0]//fishLen\n",
    "                ta = ta[:nTrls*fishLen].reshape(nTrls, fishLen,-1)\n",
    "                stimLoc = util.to_utf(grp['stimLoc'])\n",
    "                trlNum = np.arange(nTrls)\n",
    "                dic = dict(trlNum=trlNum, tailAngles=list(ta), stim=stimLoc, path=[path_hFile]*nTrls)\n",
    "            else:\n",
    "                dic = None\n",
    "        else:\n",
    "            dic=None\n",
    "    if dic is not None:\n",
    "        dic = pd.DataFrame(dic)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Extract tail angles from all datasets where behavior's been extracted already_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fishInds = np.unique(xls.FishIdx)\n",
    "dataFrame_behav = []\n",
    "for iFish, idx_fish in enumerate(fishInds):\n",
    "    print(f'Fish # {iFish}/{len(fishInds)}')\n",
    "    path_ = xls.loc[xls.FishIdx==idx_fish].Path.iloc[0]\n",
    "    df_ = get_behav_from_path(path_)\n",
    "    if df_ is not None:\n",
    "        df_ = df_.assign(fishIdx=idx_fish)\n",
    "        dataFrame_behav.append(df_)\n",
    "dataFrame_behav = pd.concat(dataFrame_behav, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Clean tail angles using SVD_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%% Clean tail angles using SVD\n",
    "trlLens = np.array([_.shape[-1] for _ in dataFrame_behav.tailAngles])\n",
    "trlLen = trlLens.min()\n",
    "ta = np.array([np.array(_)[:,:trlLen] for _ in np.array(dataFrame_behav.tailAngles)])\n",
    "nTrls = ta.shape[0]\n",
    "ta_ser = np.concatenate(ta, axis=1)\n",
    "# Clean tailAngles\n",
    "%time ta_clean, _, svd = hf.cleanTailAngles(ta_ser)\n",
    "ta_trl = np.array(np.hsplit(ta_clean, nTrls))\n",
    "dataFrame_behav = dataFrame_behav.assign(tailAngles = list(ta_trl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Re-fit the gmm_model with updated dataset, if need be*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time gmm_model = gmm_model.fit(ta_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save the GMM model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_group = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "fn = f'gmm_for_headFixed_[{gmm_model.n_gmm_}]_svd_[{gmm_model.n_svd_}]' \n",
    "fn = fn + f'_env_pca_[{gmm_model.pca.n_components_}]_{util.timestamp()}.pkl'\n",
    "\n",
    "dir_save = os.path.join(dir_group, f'session_{util.timestamp()}')\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "\n",
    "%time path_gmm = joblib.dump(gmm_model, os.path.join(dir_save, fn))[0]\n",
    "print(path_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Load pre-trained GM model and predict on all the behavrior trials_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Load the trained model\n",
    "gmm_model = joblib.load(path_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = []\n",
    "for ta_ in ta_trl:\n",
    "    lbls = gmm_model.predict(ta_)[0]\n",
    "    labels.append(lbls)\n",
    "dataFrame_behav = dataFrame_behav.assign(gmmLabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save the dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'dataFrame_headFixed_tailAngles_gmmLabels.pkl'\n",
    "%time dataFrame_behav.to_pickle(os.path.join(dir_save, fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Compute $p(l_i|t_j)$, where $l_m {\\in} \\{l_i\\}_{i=0}^{m}$ and $t_j {\\in} \\{t_j\\}_{j=1}^{n}$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.5 # bandwith in ms\n",
    "Fs_behav=500\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "ta_tot = np.array([_[-1] for _ in dataFrame_behav.tailAngles])\n",
    "lbls_trl = np.array([_ for _ in dataFrame_behav.gmmLabels])\n",
    "lbls_unique = np.unique(lbls_trl.flatten())\n",
    "\n",
    "# Get the indices of each of the labels across all trials\n",
    "lbls_inds = []\n",
    "for lbl_ in lbls_unique:\n",
    "    inds_ = np.where(lbls_trl == lbl_)[1] # Only the column inds because we want to average over time\n",
    "    lbls_inds.append(inds_)\n",
    "\n",
    "# bandwidth = int(np.round(bw*Fs_behav))\n",
    "tt = np.arange(ta_tot.shape[1])\n",
    "kde = KernelDensity(kernel='exponential', bandwidth=bw)\n",
    "func_now = lambda x: kde.fit(x[:, None]).score_samples(tt[:, None])\n",
    "with ProgressBar():\n",
    "    lbls_log_prob = dask.compute(*[dask.delayed(func_now)(inds_) for inds_ in lbls_inds])\n",
    "lbls_log_prob = np.array(lbls_log_prob)\n",
    "lbls_prob = np.array([np.exp(lp) for lp in lbls_log_prob])\n",
    "S = lbls_prob.sum(axis=0)[None, :]\n",
    "lbls_prob_norm = lbls_prob/S\n",
    "\n",
    "# Centers of mass for each labels probability distribution over time\n",
    "coms = []\n",
    "for p in lbls_prob_norm:    \n",
    "    coms.append(np.argmax(p))    \n",
    "coms = np.array(coms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Plot the label probabilities over time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPreStim=499\n",
    "Fs_behav=500\n",
    "xl = (-0.1, 0.5)\n",
    "fn = f'Fig-{util.timestamp()}_GMM label probabilities over trial time_bw[{bw}]_notNorm'\n",
    "\n",
    "inds_sort_pkTime = np.argsort(coms)\n",
    "plt.style.use(('seaborn-darkgrid', 'seaborn-talk', 'seaborn-ticks'))\n",
    "t_now = (tt-nPreStim)*(1/Fs_behav)\n",
    "coms_t = (coms-nPreStim)*(1/Fs_behav)\n",
    "nLbls = len(lbls_unique)\n",
    "X = lbls_prob_norm[inds_sort_pkTime]\n",
    "yl = (-0.1, lbls_prob_norm.max()+0.1)\n",
    "clrMap = plt.cm.tab20(spt.standardize(np.arange(nLbls)))\n",
    "fh, ax = plt.subplots(nLbls, 1, figsize=(10, 2*nLbls), sharex=True, sharey=False)\n",
    "for iLbl, ax_ in enumerate(ax):\n",
    "    ax_.plot(t_now, X[iLbl], c= clrMap[iLbl], label=f'$label={inds_sort_pkTime[iLbl]}$')      \n",
    "    ax_.legend(loc='upper right', fontsize=16)\n",
    "    ax_.axvline(coms_t[inds_sort_pkTime[iLbl]], color='k', ls='--', alpha=0.2)\n",
    "    ax_.axvline(0, color='r', ls='--', alpha=0.5)\n",
    "# ax_.set_xlim(xl)\n",
    "ax_.set_ylim(yl)\n",
    "ax_.set_xlabel('Time (s)', fontsize=18)\n",
    "ax_.set_ylabel('$Probability$', fontsize=18)\n",
    "fh.suptitle('Probabilities of GMM labels', fontsize=22)\n",
    "fh.subplots_adjust(top=0.96)\n",
    "fh.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n",
    "fh.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "print(f'Figure saved at {dir_save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lbls_prob_norm.sum(axis=0),'.')\n",
    "plt.savefig(os.path.join(dir_save, 'probSumOverTime.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPreStim=499\n",
    "Fs_behav=500\n",
    "xl = (-0.2, 0.6)\n",
    "fn = f'Fig-{util.timestamp()}_GMM label probabilities over trial time_ordered by prob peak time_bw[{bw}]'\n",
    "\n",
    "inds_sort_pkTime = np.argsort(-coms)\n",
    "plt.style.use(('seaborn-ticks', 'seaborn-talk'))\n",
    "t_now = (tt-nPreStim)*(1/Fs_behav)\n",
    "coms_t = (coms-nPreStim)*(1/Fs_behav)\n",
    "nLbls = len(lbls_unique)\n",
    "X = lbls_prob[inds_sort_pkTime]\n",
    "clrMap = plt.cm.tab20(spt.standardize(np.arange(nLbls)))\n",
    "\n",
    "fh = plt.figure(figsize=(20, 10))\n",
    "for iLbl, x in enumerate(X):\n",
    "    if iLbl==0:\n",
    "        x_prev = 0\n",
    "        x_now = x\n",
    "    else:\n",
    "        x_prev = x_now\n",
    "        x_now = x_prev + x\n",
    "    plt.fill_between(t_now, x_prev, x_now, color = clrMap[iLbl],\n",
    "                     label=f'${inds_sort_pkTime[iLbl]}$', alpha=0.5)      \n",
    "plt.legend(loc='upper right', fontsize=16, bbox_to_anchor=(1.1, 1))\n",
    "plt.xlim(xl)\n",
    "plt.ylim(-0.001, X.max()+0.02)\n",
    "plt.xlabel('Time (s)', fontsize=18)\n",
    "plt.ylabel('$Probability$', fontsize=18)\n",
    "plt.suptitle('Probabilities of GMM labels', fontsize=22)\n",
    "plt.subplots_adjust(top=0.96)\n",
    "fh.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n",
    "fh.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "print(f'Figure saved at {dir_save}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Compute label probabilities separately for head and tail trials for comparison*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of each of the labels across all trials\n",
    "stims = np.array([_[-1] for _ in dataFrame_behav.stim])\n",
    "trls_head = np.where(stims=='h')[0]\n",
    "trls_tail = np.where(stims=='t')[0]\n",
    "\n",
    "lbls_inds_head, lbls_inds_tail = [], []\n",
    "for lbl_ in lbls_unique:\n",
    "    inds_ = np.where(lbls_trl[trls_head] == lbl_)[1] # Only the column inds because we want to average over time\n",
    "    lbls_inds_head.append(inds_)\n",
    "    inds_ = np.where(lbls_trl[trls_tail]==lbl_)[1]\n",
    "    lbls_inds_tail.append(inds_)\n",
    "\n",
    "# bandwidth = int(np.round(bw*Fs_behav))\n",
    "tt = np.arange(ta_tot.shape[1])\n",
    "kde = KernelDensity(kernel='exponential', bandwidth=bw)\n",
    "func_now = lambda x: kde.fit(x[:, None]).score_samples(tt[:, None])\n",
    "with ProgressBar():\n",
    "    lbls_log_prob_head = dask.compute(*[dask.delayed(func_now)(inds_) for inds_ in lbls_inds_head])\n",
    "\n",
    "with ProgressBar():\n",
    "    lbls_log_prob_tail = dask.compute(*[dask.delayed(func_now)(inds_) for inds_ in lbls_inds_tail])\n",
    "lbls_log_prob_head = np.array(lbls_log_prob_head)\n",
    "lbls_log_prob_tail = np.array(lbls_log_prob_tail)\n",
    "lbls_prob_head = np.array([np.exp(lp) for lp in lbls_log_prob_head])\n",
    "lbls_prob_tail = np.array([np.exp(lp) for lp in lbls_log_prob_tail])\n",
    "S_head = lbls_prob_head.sum(axis=0)[None, :]\n",
    "S_tail = lbls_prob_tail.sum(axis=0)[None, :]\n",
    "lbls_prob_norm_head = lbls_prob_head/S_head\n",
    "lbls_prob_norm_tail = lbls_prob_tail/S_tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Plot the label probabilities over time separately for head and tail trials*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'Fig-{util.timestamp()}_GMM label probabilities over trial time_head and tail trls separated'\n",
    "\n",
    "plt.style.use(('seaborn-white', 'fivethirtyeight', 'seaborn-talk'))\n",
    "t_now = (tt-499)*(1/500)\n",
    "\n",
    "nLbls = len(lbls_unique)\n",
    "fh, ax = plt.subplots(nLbls, 1, figsize=(10, 2*nLbls), sharex=True, sharey=False)\n",
    "for iLbl, ax_ in enumerate(ax):\n",
    "    if iLbl ==0:\n",
    "        ax_.plot(t_now, lbls_prob_head[iLbl], c= plt.cm.tab10(0), label=f'$Head$', alpha=0.5)\n",
    "        ax_.plot(t_now, lbls_prob_tail[iLbl], c= plt.cm.tab10(1), label=f'$Tail$', alpha=0.5)\n",
    "        ax_.legend(loc='upper right', fontsize=16)\n",
    "    else:\n",
    "        ax_.plot(t_now, lbls_prob_head[iLbl], c= plt.cm.tab10(0), alpha=0.5)\n",
    "        ax_.plot(t_now, lbls_prob_tail[iLbl], c= plt.cm.tab10(1), alpha=0.5)\n",
    "    ax_.set_title(f'$Label = {iLbl}$', fontsize=16)\n",
    "ax_.set_xlim(-0.5, 5)\n",
    "# ax_.set_ylim(-0.1, lbls_prob_head.max()+0.1)\n",
    "ax_.set_xlabel('Time (s)', fontsize=18)\n",
    "ax_.set_ylabel('$Probability$', fontsize=18)\n",
    "fh.suptitle('Probabilities of GMM labels_head vs tail', fontsize=22)\n",
    "fh.subplots_adjust(top=0.96)\n",
    "# fh.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n",
    "# fh.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "print(f'Figure saved at {dir_save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_means = gmm_model.gmm.means_\n",
    "gmm_cov = gmm_model.gmm.covariances_\n",
    "similarity_means = np.corrcoef(gmm_means[inds_sort_pkTime])\n",
    "sim = np.argpartition(similarity_means, 2)\n",
    "# inds_sort_means = np.argsort(similarity_means, axis=1)\n",
    "tril = np.tril(similarity_means)\n",
    "sns.heatmap(tril, vmin=-1, vmax=1)\n",
    "# sns.heatmap(similarity_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_sort_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Interactive HTML plots with plotly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Check ouf a few trials with predictions from the GMM with annotated markers\n",
    "\n",
    "# iTrl = 10  # (Struggles = {9, 11}\n",
    "# iTrl = np.random.choice(np.arange(df.shape[0]),size = 1)[0]\n",
    "yShift = 1.1\n",
    "loop = False\n",
    "xl = (-0.1, 2)\n",
    "# xl = 'auto'\n",
    "figDir = os.path.join(dir_save, 'interactiveFigs')\n",
    "onOffThr = 0\n",
    "figExts = ('png','pdf')\n",
    "cmap = plt.cm.tab20\n",
    "dt_behav = 1/500\n",
    "pre_behav = 500\n",
    "figSize = (100, 10)\n",
    "\n",
    "\n",
    "ta_trl = np.array([np.array(_) for _ in dataFrame_behav.tailAngles])\n",
    "\n",
    "if not os.path.exists(figDir):\n",
    "    os.mkdir(figDir)\n",
    "    \n",
    "scaler_clrs = Scaler(standardize =True).fit(np.arange(gmm_model.n_gmm_))   \n",
    "\n",
    "trls = np.arange(ta_trl.shape[0])    \n",
    "# maxEnv_full = spt.emd.envelopesAndImf(ta[-1])['env']['max']\n",
    "\n",
    "trls = [70, 71, 73, 74, 75]\n",
    "for iTrl in trls:\n",
    "    ta_now = ta_trl[iTrl]\n",
    "    x = (np.arange(ta_now.shape[1])-499)*dt_behav\n",
    "    y = ta_now[-1]\n",
    "    y = y-y[0]\n",
    "    lbls, _ = gmm_model.predict(ta_now)\n",
    "    line = go.Scatter(x=x, y = y, mode='lines', opacity = 0.2, marker = dict(color='black'), name='ta')\n",
    "    scatters = []\n",
    "    scatters.append(line)\n",
    "    for iLbl, lbl in enumerate(np.unique(lbls)):\n",
    "        clr = f'rgba{cmap(lbl)}'\n",
    "        inds= np.where(lbls==lbl)[0]\n",
    "        scatter = go.Scatter(x=x[inds], y=y[inds], mode='markers', marker=dict(color=clr, symbol=lbl, size=10),\n",
    "                             name = f'Lbl-{lbl}')\n",
    "        scatters.append(scatter)\n",
    "    fig = go.Figure(scatters)\n",
    "    fig.update_layout(title = f'Tail angles with GMM labels, trl = {iTrl}, stim = {(stims[iTrl]).upper()}')\n",
    "#     fig.show()\n",
    "    figName = f'Fig-{util.timestamp()}_trl-{iTrl}.html'\n",
    "    fig.write_html(os.path.join(figDir,figName))\n",
    "print(figDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot GMM labels --> Markers map\n",
    "x = np.arange(gmm_model.n_gmm_)\n",
    "y = np.ones_like(x)\n",
    "scatters = []\n",
    "for ind, x_ in enumerate(x):\n",
    "    clr = f'rgba{cmap(x_)}'\n",
    "    scatter = go.Scatter(x= [x_], y = [y[ind]], mode = 'markers',\n",
    "                         marker = dict(symbol = x_, size = 20, color = clr), name = f'Lbl-{x_}')\n",
    "    scatters.append(scatter)\n",
    "fig = go.Figure(scatters)\n",
    "fig.update_xaxes(tickvals = x)\n",
    "fig.update_yaxes(tickvals = [])\n",
    "fig.update_layout(title='Symbol map: GMM labels to markers and colors', xaxis_title=\"GMM label\")\n",
    "fig.show()\n",
    "# figName = f'Fig-{util.timestamp()}_scatterPlotMarkerGmmLabelLegend.html'\n",
    "# fig.write_html(os.path.join(figDir,figName), auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls_of_interest = [18, 14, 1, 6, 11, 19, 15, 8]\n",
    "lbl_names = ['Fast-large_struggle', 'Fast-large-escape', 'Medium slow',\n",
    "             'Medium slow', 'Medium slow', 'Slow', 'Slow', 'Flicks']\n",
    "tKer = 50e-3\n",
    "\n",
    "labels=np.array(labels)\n",
    "likelihood_swim = np.log2(np.abs(ta[:,-1,:]).mean(axis=0))\n",
    "impulses_lbls = []\n",
    "for lbl in lbls_of_interest:\n",
    "    foo = np.zeros_like(labels)\n",
    "    foo[np.where(labels==lbl)]=1\n",
    "    impulses_lbls.append(foo)\n",
    "impulses_lbls = np.array(impulses_lbls)\n",
    "stimLoc = np.array(dataFrame_behav.stim)\n",
    "trls_head = np.where(stimLoc=='h')[0]\n",
    "trls_tail = np.where(stimLoc=='t')[0]\n",
    "\n",
    "impulses_lbls_head = impulses_lbls[:, trls_head]\n",
    "impulses_lbls_tail = impulses_lbls[:, trls_tail]\n",
    "foo_head = impulses_lbls_head.sum(axis=1)\n",
    "foo_tail = impulses_lbls_tail.sum(axis=1)\n",
    "nKer = int(tKer*500)\n",
    "P_head, P_tail = [], [] \n",
    "for lbl in foo_head:\n",
    "    lbl_conv = spt.causalConvWithSemiGauss1d(lbl, nKer)\n",
    "    P_head.append(lbl_conv)\n",
    "    \n",
    "for lbl in foo_tail:\n",
    "    lbl_conv = spt.causalConvWithSemiGauss1d(lbl, nKer)\n",
    "    P_tail.append(lbl_conv)\n",
    "\n",
    "P_head, P_tail = np.array(P_head), np.array(P_tail)\n",
    "tot = P_head.sum() + P_tail.sum()\n",
    "P_head /= trls_head.shape[0]\n",
    "P_tail /= trls_tail.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(likelihood_swim)\n",
    "plt.xlim(0, len(likelihood_swim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(P_head.shape[1])*(1/500)*1000\n",
    "fh, ax = plt.subplots(P_head.shape[0],1, figsize=(20, 20), sharex=True, sharey=True)\n",
    "count = 0\n",
    "for head, tail in zip(P_head, P_tail):\n",
    "#     ax[count].plot(x, np.log2(head+1e-6), c=plt.cm.tab10(0))\n",
    "#     ax[count].plot(x, np.log2(tail+1e-6), c=plt.cm.tab10(1))\n",
    "    ax[count].plot(x, head, c=plt.cm.tab10(2))\n",
    "    ax[count].plot(x, tail, c=plt.cm.tab10(3))\n",
    "#     ax[count].set_ylabel(f'Label # {lbls_of_interest[count]}')\n",
    "    ax[count].set_ylabel(f'{lbl_names[count]}', rotation=45)\n",
    "    count +=1\n",
    "ax[count-1].set_xlim(800, 3000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
