{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, warnings, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import dask\n",
    "import h5py\n",
    "import joblib\n",
    "# from skimage.external import tifffile as tff\n",
    "import tifffile as tff\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "codeDir = r'\\\\dm11\\koyamalab/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.behavior.FreeSwimBehavior as fsb\n",
    "import apCode.behavior.headFixed as hf\n",
    "import apCode.SignalProcessingTools as spt\n",
    "\n",
    "from apCode import util as util\n",
    "\n",
    "from apCode.behavior import gmm as my_gmm\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 143\n",
    "random.seed = seed\n",
    "\n",
    "\n",
    "plt.style.use(('fivethirtyeight', 'seaborn-talk'))\n",
    "plt.figure()\n",
    "plt.close()\n",
    "\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "dir_group = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "\n",
    "file_xls = 'GCaMP volumetric imaging summary.xlsx'\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Get all fish paths and check for dataframes in each path\n",
    "inds_fish = np.array(xls.FishIdx.dropna())\n",
    "pathList = np.array([xls.loc[xls.FishIdx == ind].Path.iloc[0] for ind in inds_fish])\n",
    "\n",
    "paths_df = []\n",
    "paths_hFile = []\n",
    "for path_ in pathList:\n",
    "    file = ft.findAndSortFilesInDir(path_, ext = 'pickle', search_str='dataFrame')\n",
    "    if len(file)>0:\n",
    "        paths_df.append(os.path.join(path_, file[-1]))\n",
    "    file = ft.findAndSortFilesInDir(path_, ext = 'h5', search_str='procData')\n",
    "    if len(file)>0:\n",
    "        paths_hFile.append(os.path.join(path_, file[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load available tail angles and clean wiwht wavelet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read tail angles from all the available HDF files\n",
    "%time dic_ta = hf.tailAngles_from_hdf_concatenated_by_trials(pathList)\n",
    "ta = np.concatenate(dic_ta['tailAngles'], axis=1)\n",
    "%time ta, _, svd  = hf.cleanTailAngles(ta, dt=1/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%$ Save data for later access\n",
    "\n",
    "dic_ta['tailAngles_clean'] = ta.copy()\n",
    "%time np.save(os.path.join(dir_group, 'tailAngles_clean.npy'), dic_ta)\n",
    "%time joblib.dump(svd, os.path.join(dir_group,'svd_object_tailAngles.pkl'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%% Reload data to continue from here\n",
    "fName = 'tailAngles_clean.npy'\n",
    "dic_ta = np.load(os.path.join(dir_group, fName), allow_pickle = True)[()]\n",
    "ta_clean = dic_ta['tailAngles_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract features (for GMM) from tail angle timeseries\n",
    "hpf = 1\n",
    "dt_behav = 1/500\n",
    "\n",
    "%time df_features = hf.swimEnvelopes_multiLoc(ta_clean)\n",
    "arr_feat = np.array(df_features)\n",
    "labels_feat = df_features.columns\n",
    "ta_tot = ta_clean[-1]\n",
    "ta_tot = spt.chebFilt(ta_clean[-1], dt_behav, hpf, btype = 'highpass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "onOffThr = 3 # Threshold for swim onset of offset in maximum of envelopes\n",
    "t_smooth = 30e-3 # Smoothing kernel length in ms\n",
    "nKer = int(np.round(t_smooth*(1/dt_behav)))\n",
    "\n",
    "scaler = StandardScaler(with_mean=False).fit(arr_feat)\n",
    "polarity = np.zeros_like(ta_tot)\n",
    "envelopes = spt.emd.envelopesAndImf(ta_tot, interp_kind = 'quadratic')['env']\n",
    "polarity[np.where(envelopes['crests']>onOffThr)]=1\n",
    "polarity[np.where(envelopes['troughs']<-onOffThr)]=-1\n",
    "maxEnv = envelopes['max']\n",
    "arr_feat_scaled = scaler.transform(arr_feat)\n",
    "\n",
    "arr_feat_scaled = np.array(dask.compute(*[dask.delayed(spt.causalConvWithSemiGauss1d)(x, nKer*2)\\\n",
    "                   for x in arr_feat_scaled.T])).T\n",
    "\n",
    "# arr_feat_scaled = np.c_[polarity, arr_feat_scaled] # Hoping that incorporating the polarity vector\n",
    "#                                                    # will help GMM distinguish by turn direction\n",
    "    \n",
    "inds_supraThresh = np.where(maxEnv > onOffThr)[0]\n",
    "arr_feat_supra = arr_feat_scaled[inds_supraThresh,:]\n",
    "\n",
    "path_ = os.path.join(dir_group, 'standardScaler.pkl')\n",
    "joblib.dump(scaler,path_);\n",
    "print(f'Saved standard scaler at\\n {path_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subSample = 5\n",
    "comps = np.arange(1,36)\n",
    "\n",
    "X = arr_feat_supra[::subSample,:]\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X,comps = comps)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "x = np.arange(len(out['aic'])) + 1\n",
    "plt.plot(comps, out['aic'],'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, out['bic'],'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Try computing GMM metrics for dimensionality reduced feature array\n",
    "\n",
    "pca = PCA(n_components = 0.95, random_state = 143)\n",
    "%time X_pca = pca.fit_transform(X)\n",
    "print(f'Number of reduced features = {X_pca.shape[1]}')\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X_pca,comps = comps)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(comps, spt.standardize(out['aic']),'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, spt.standardize(out['bic']),'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Fit GMM model with specified number of components, predict labels for data, \n",
    "## and plot in low dimensions with PCA using labels as colors\n",
    "n_comps = 10\n",
    "subSample = 4\n",
    "alpha = 0.5\n",
    "\n",
    "X = arr_feat_supra[::subSample,:]\n",
    "\n",
    "%time gmm = mlearn.GMM(n_components= n_comps, covariance_type='full', random_state=143,\\\n",
    "                       n_init=3, verbose = 0).fit(X_pca)\n",
    "%time labels = gmm.predict(X_pca)\n",
    "# orderedLabels = gmm.sorted_labels() # This will be used to orer labels in subsequent uses\n",
    "# labels_sorted = gmm.relabel_by_norm(labels)\n",
    "\n",
    "pca = PCA(n_components = 3, random_state = 143)\n",
    "%time x_pca = pca.fit_transform(X_pca)\n",
    "\n",
    "fh,ax = plt.subplots(2,2,figsize = (15,10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# clrs = [plt.cm.tab10(_) for _ in labels_sorted]\n",
    "# clrs = plt.cm.tab20(labels_sorted)\n",
    "inds = np.linspace(0,1,n_comps)\n",
    "clrs = plt.cm.nipy_spectral(inds)[labels_sorted]\n",
    "\n",
    "ax[0].scatter(x_pca[:,0], x_pca[:,1], s = 10, c = clrs, alpha = alpha)\n",
    "ax[0].set_xlabel('pca 1')\n",
    "ax[0].set_ylabel('pca 2')\n",
    "\n",
    "ax[1].scatter(x_pca[:,0], x_pca[:,2], s = 10, c = clrs, alpha = alpha)\n",
    "ax[1].set_xlabel('pca 1')\n",
    "ax[1].set_ylabel('pca 3')\n",
    "\n",
    "ax[2].scatter(x_pca[:,1], x_pca[:,2], s = 10, c = clrs, alpha = alpha)\n",
    "ax[2].set_xlabel('pca 2')\n",
    "ax[2].set_ylabel('pca 3')\n",
    "fh.tight_layout()\n",
    "\n",
    "clrs = plt.cm.nipy_spectral(inds)\n",
    "x = np.arange(len(orderedLabels))\n",
    "y = np.ones_like(orderedLabels)\n",
    "plt.figure(figsize = (20,5))\n",
    "plt.scatter(x,y, c= clrs,s =2000, marker = 's')\n",
    "plt.yticks([])\n",
    "plt.xticks(x, fontsize = 20);\n",
    "plt.title('Norm-ordered colors', fontsize = 20)\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save fitted gmm model\n",
    "joblib.dump(gmm, os.path.join(dir_group, f'group_fitted_gmm_{util.timestamp()}.pkl'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Fit GMM on tail angles from multiple fish and save the fitter\n",
    "n_gmm = 15\n",
    "\n",
    "%time fitter = my_gmm.train_on_tailAngles(ta_clean, n_gmm=n_gmm)\n",
    "n_pca = fitter['pca'].n_components_\n",
    "n_gmm = fitter['gmm'].n_components\n",
    "\n",
    "joblib.dump(fitter, os.path.join(dir_group, f'gmm_fitter_object_pca-{n_pca}_gmm-{n_gmm}_{util.timestamp()}.pkl'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trlLen = 4000\n",
    "iTrl = 132\n",
    "\n",
    "%matplotlib qt\n",
    "inds = np.arange(trlLen*(iTrl-1), trlLen*iTrl)\n",
    "ta_sub = ta_clean[:,inds]\n",
    "labels, arr_feat = my_gmm.predict_on_tailAngles(ta_sub, fitter)\n",
    "\n",
    "y = ta_sub[-1]\n",
    "x = np.arange(len(y))\n",
    "clrs = labels/fitter['gmm'].n_components\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x,y, lw = 0.5, c= 'k')\n",
    "plt.scatter(x,y,c = plt.cm.tab20(clrs), s= 10)\n",
    "# plt.xlim(0, 1000)\n",
    "plt.ylim(-200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_svd = 'svd_object_tailAngles.pkl'\n",
    "path_svd = os.path.join(dir_group, file_svd)\n",
    "foo = joblib.load(path_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Try computing GMM metrics for dimensionality reduced feature array\n",
    "\n",
    "comps = np.arange(1,31)\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X_svd, comps = comps)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(comps, spt.standardize(out['aic']),'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, spt.standardize(out['bic']),'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% How many components to use\n",
    "n_svd = 3\n",
    "comps = np.arange(5, 26)\n",
    "%matplotlib inline\n",
    "%time X_svd, svd = my_gmm.tailAngles_to_svd_featureArray(ta_clean,n_svd= n_svd, use_envelopes=True)\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X_svd,comps = comps, warm_start = True)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(comps, spt.standardize(out['aic']),'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, spt.standardize(out['bic']),'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SVD based fitter\n",
    "fName = f'gmm_fitter_svd-{fitter[\"svd\"].n_components}_gmm-{fitter[\"gmm\"].n_components}.pkl'\n",
    "\n",
    "%time fitter = my_gmm.train_on_tailAngles_svd(ta_clean, n_gmm = 22, n_svd =3, use_envelopes=True)\n",
    "\n",
    "### Save the fitter\n",
    "%time joblib.dump(fitter, os.path.join(dir_group, fName))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% How many components to use\n",
    "n_svd = 3\n",
    "comps = np.arange(20, 31)\n",
    "%matplotlib inline\n",
    "%time X_svd, svd = my_gmm.tailAngles_to_svd_featureArray(ta_clean,n_svd= n_svd, use_envelopes=True)\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X_svd,comps = comps, warm_start = True)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(comps, spt.standardize(out['aic']),'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, spt.standardize(out['bic']),'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the above, but use PCA to reduce dimensionality beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Demo that PCA does not influence GMM components\n",
    "# x, y = make_blobs(n_samples=1000, centers=[(4,3,0,0), (10,-1, 2,0),(11, -17, 1,0), (-13, 27, 0,0)])\n",
    "# x += np.random.randn(*x.shape)*0.1\n",
    "# x_pca = PCA(n_components=0.99).fit_transform(x)\n",
    "# print(x.shape, x_pca.shape)\n",
    "# print(np.unique(y))\n",
    "\n",
    "# comps = np.arange(1,11)\n",
    "# %time foo = mlearn.gmm_information_vs_nComponents(x, comps= comps)\n",
    "# %time foo_pca = mlearn.gmm_information_vs_nComponents(x, comps= comps)\n",
    "\n",
    "# plt.figure(figsize = (10,5))\n",
    "# plt.subplot(121)\n",
    "# plt.plot(comps,foo['aic'],'.-', label = 'aic')\n",
    "# plt.plot(comps, foo['bic'],'.-', label = 'bic')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.plot(comps,foo_pca['aic'],'.-', label = 'aic')\n",
    "# plt.plot(comps, foo_pca['bic'],'.-', label = 'bic')\n",
    "# plt.legend()\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% How many components to use\n",
    "n_svd = 3\n",
    "comps = np.arange(20, 31)\n",
    "%matplotlib inline\n",
    "%time X_svd, svd = my_gmm.tailAngles_to_svd_featureArray(ta_clean,n_svd= n_svd, use_envelopes=True)\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X_svd,comps = comps, warm_start = True)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(comps, spt.standardize(out['aic']),'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, spt.standardize(out['bic']),'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New and improved SVD based GMM model with PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_svd = 3\n",
    "n_gmm = 20\n",
    "use_envelopes = True\n",
    "pca_percVar = 0.98\n",
    "verbose = 1\n",
    "\n",
    "gmm_env = my_gmm.SvdGmm(n_svd = n_svd,use_envelopes=use_envelopes,pca_percVar=pca_percVar,n_gmm=n_gmm,\n",
    "                        verbose = verbose)\n",
    "%time gmm_env = gmm_env.fit(ta_clean)\n",
    "%time labels, features = gmm_env.predict(ta_clean)\n",
    "\n",
    "#-- Save model\n",
    "file_model = f'gmm_svd-{n_svd}_env_pca-{gmm_env.pca.n_components_}_gmm-{n_gmm}_{util.timestamp()}.pkl'\n",
    "joblib.dump(gmm_env, os.path.join(dir_group, file_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Save model\n",
    "file_model = f'gmm_svd-{n_svd}_env_pca-{gmm_env.pca.n_components_}_gmm-{n_gmm}_{util.timestamp()}.pkl'\n",
    "joblib.dump(gmm_env, os.path.join(dir_group, file_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(dir_group, file_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% How many components to use\n",
    "n_svd = 3\n",
    "comps = np.arange(17, 31)\n",
    "pca_percVar = 0.99\n",
    "\n",
    "%matplotlib inline\n",
    "%time X_svd, svd = my_gmm.tailAngles_to_svd_featureArray(ta_clean,n_svd= n_svd, use_envelopes=True)\n",
    "\n",
    "%time X_svd_pca = PCA(n_components=pca_percVar).fit_transform(X_svd)\n",
    "print(f'Reduced to {X_svd_pca.shape[1]} pca components')\n",
    "\n",
    "%time out = mlearn.gmm_information_vs_nComponents(X_svd_pca,comps = comps, warm_start = False)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(comps, spt.standardize(out['aic']),'o-', alpha = 0.5, label = 'AIC')\n",
    "plt.plot(comps, spt.standardize(out['bic']),'o-', alpha = 0.5, label = 'BIC')\n",
    "plt.xticks(comps)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SVD based fitter\n",
    "%time fitter_svd_pca = my_gmm.train_on_tailAngles_svd(ta_clean, n_gmm = 22, n_svd =3, use_envelopes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['\\\\alpha', '\\\\beta', '\\gamma', '\\sigma','\\infty', \\\n",
    "            '\\spadesuit', '\\heartsuit', '\\diamondsuit', '\\clubsuit', \\\n",
    "            '\\\\bigodot', '\\\\bigotimes', '\\\\bigoplus', '\\imath', '\\\\bowtie', \\\n",
    "            '\\\\bigtriangleup', '\\\\bigtriangledown', '\\oslash' \\\n",
    "           '\\ast', '\\\\times', '\\circ', '\\\\bullet', '\\star', '+', \\\n",
    "            '\\Theta', '\\Xi', '\\Phi', \\\n",
    "            '\\$', '\\#', '\\%', '\\S']\n",
    "def getMarker(i):\n",
    "    # Use modulus in order not to have the index exceeding the length of the list (markers)\n",
    "    return \"$\"+markers[i % len(markers)]+\"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trlLen = 4000\n",
    "iTrl = 99\n",
    "cmap = plt.cm.nipy_spectral_r\n",
    "plt.style.use(('seaborn-white'))\n",
    "\n",
    "%matplotlib auto\n",
    "inds = np.arange(trlLen*(iTrl-1), trlLen*iTrl)\n",
    "ta_sub = ta_clean[:,inds]\n",
    "\n",
    "labels, X = my_gmm.predict_on_tailAngles_svd(ta_sub, fitter)\n",
    "\n",
    "y = ta_sub[-1]\n",
    "x = np.arange(len(y))\n",
    "clrs = labels/fitter['gmm'].n_components\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x,y, lw = 0.5, c= 'k')\n",
    "lbls_unique = np.unique(labels)\n",
    "for lbl in lbls_unique:\n",
    "    inds = np.where(labels==lbl)[0]\n",
    "#     plt.scatter(x[inds],y[inds],c = 'k', s = 200,marker = getMarker(lbl), alpha = 0.5)\n",
    "    plt.scatter(x[inds],y[inds],c = 'k', s = 200,marker = r\"${}$\".format(str(lbl)), alpha = 0.5)\n",
    "# plt.scatter(x,y, s= 20, c = clrs)\n",
    "# plt.xlim(0, 1000)\n",
    "plt.ylim(-200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,X = my_gmm.predict_on_tailAngles_svd(ta_clean, fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.98).fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% State matrix\n",
    "m = labels.max()+1\n",
    "n  = len(labels)\n",
    "T = np.zeros((m,n))\n",
    "F = T.copy()\n",
    "t = np.arange(len(labels))\n",
    "T[labels,t] = 1\n",
    "F[labels,t]= labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(F, aspect = 'auto', cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = PCA(n_components=2).fit_transform(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_pca[:,0], X_pca[:,1],'.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(foo[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.pinv(np.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
