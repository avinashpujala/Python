{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import caiman as cm\n",
    "import h5py\n",
    "# from skimage.external import tifffile as tff\n",
    "from sklearn.decomposition import PCA\n",
    "import tifffile as tff\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "codeDir = r'V:/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.behavior.FreeSwimBehavior as fsb\n",
    "import apCode.behavior.headFixed as hf\n",
    "import apCode.SignalProcessingTools as spt\n",
    "import apCode.geom as geom\n",
    "import importlib\n",
    "from apCode import util as util\n",
    "from apCode import hdf\n",
    "from apCode.imageAnalysis.spim import regress\n",
    "from apCode.behavior import gmm as my_gmm\n",
    "from apCode.machineLearning.preprocessing import Scaler\n",
    "import rsNeuronsProj.util as rsp\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 143\n",
    "random.seed = seed\n",
    "\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read the xls sheet with all the data paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_xls = r'Y:\\Avinash\\Projects\\RS recruitment\\GCaMP imaging'\n",
    "file_xls = 'GCaMP volumetric imaging summary.xlsx'\n",
    "xls = pd.read_excel(os.path.join(dir_xls, file_xls), sheet_name='Sheet1')\n",
    "xls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Filter dataframe to keep good ones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_sub = xls.loc[xls.RoiSet==1]\n",
    "print(xls_sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read roi_ts dataframes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = []\n",
    "for iPath, path_ in enumerate(xls_sub.Path):\n",
    "    pp = glob.glob(os.path.join(path_, 'roi_ts*.pkl'))\n",
    "    if len(pp)==0:\n",
    "        print(f'Dataframe not found in {path_}')\n",
    "    else:\n",
    "        df_ = pd.read_pickle(pp[-1])\n",
    "        df_ = df_.assign(fishIdx=iPath, path=pp[0])\n",
    "        dataFrame.append(df_)\n",
    "dataFrame = pd.concat(dataFrame, axis=0, ignore_index=True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Fix naming errors\n",
    "roiNames_all = np.array(dataFrame.roiName)\n",
    "roiNames_all = [_.replace('RoV2', 'RoV3') for _ in roiNames_all]\n",
    "roiNames_all = [_.replace('Rov3', 'RoV3') for _ in roiNames_all]\n",
    "roiNames_all = [_.replace('Rom2', 'RoM2') for _ in roiNames_all]\n",
    "\n",
    "# inds = util.findStrInList('RoV2', roiNames_all)\n",
    "# rn_now = [_.replace('RoV2', 'Rov3') for _ in roiNames_all[inds]]\n",
    "# roiNames_all[inds] = rn_now\n",
    "dataFrame = dataFrame.assign(roiName=roiNames_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Plot_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _First plot trial averaged Ca2+ responses across oll fish_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPre = 3\n",
    "sf = 5000\n",
    "roiNames_all = np.array(dataFrame.roiName)\n",
    "roiNames_core = np.array([_.split('.')[1] for _ in np.unique(roiNames_all)])\n",
    "roiNames_core = np.unique(roiNames_core)\n",
    "roiNames_core = roiNames_core[rsp.bing.omitRois(roiNames_core, ['LL'])]\n",
    "roi_dict = dict(mu=[], sem=[], name=[], stim=[], peak=[])\n",
    "for rn in roiNames_core:\n",
    "    for side in ['L', 'R']:\n",
    "        for stim in ['h', 't']:\n",
    "            rn_now = f'{side}.{rn}'    \n",
    "            inds = util.findStrInList(rn_now, roiNames_all)\n",
    "            if len(inds)==0:\n",
    "                print(f'No roi by that name: {rn_now}')\n",
    "            else:\n",
    "                df_sub = dataFrame.iloc[inds]\n",
    "                ca_ = np.array([np.array(_) for _ in df_sub.loc[df_sub.stimLoc==stim].ca])\n",
    "                f0 = np.median(ca_[:,:nPre], axis=1)[:, None]\n",
    "                ca_ = ca_-f0\n",
    "                mu = ca_.mean(axis=0)\n",
    "                sem = mu/np.sqrt(ca_.shape[0])\n",
    "                pks = np.round((ca_.max(axis=1)*sf)*100)/100\n",
    "                roi_dict['mu'].append(mu)\n",
    "                roi_dict['sem'].append(sem)\n",
    "                roi_dict['name'].append(rn_now)\n",
    "                roi_dict['stim'].append(stim)\n",
    "                roi_dict['peak'].append(pks)\n",
    "df_roi_mu = pd.DataFrame(roi_dict)\n",
    "# print(np.unique(dataFrame.iloc[inds].path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nRows = int(df_roi_mu.shape[0]/2)\n",
    "# nCols = 2\n",
    "sz = 15\n",
    "fh, ax = plt.subplots(nrows=nRows, ncols=nCols, figsize=(sz, int(0.35*sz*nRows/nCols)), sharex=True,\n",
    "                      sharey='row')\n",
    "fh.tight_layout()\n",
    "for iRow, rn in enumerate(roiNames_core):\n",
    "    for iSide, side in enumerate([\"L\", \"R\"]):        \n",
    "        rn_now = f'{side}.{rn}'\n",
    "        for iStim, stim in enumerate(['h', 't']):\n",
    "            df_ = df_roi_mu.loc[(df_roi_mu.name==rn_now) & (df_roi_mu.stim==stim)]\n",
    "            mu = np.array(df_['mu'])[0]*1000*5\n",
    "            sem = np.array(df_['sem'])[0]*1000*5\n",
    "            x = np.arange(len(mu))*(1/2)\n",
    "            if (iRow==0) & (iSide==0):\n",
    "                if stim=='h':\n",
    "                    lbl = 'Head'\n",
    "                else:\n",
    "                    lbl = 'Tail'\n",
    "                ax[iRow, iSide].fill_between(x, mu-sem, mu+sem, color=plt.cm.tab10(iStim),\n",
    "                                             alpha=0.3, label=lbl)\n",
    "                ax[iRow, iSide].legend(loc='best')\n",
    "                ax[iRow, iSide].set_ylabel('$\\Delta F/F_0$ (100x)')\n",
    "            else:                \n",
    "                ax[iRow, iSide].fill_between(x, mu-sem, mu+sem, color=plt.cm.tab10(iStim), alpha=0.3)\n",
    "            ax[iRow, iSide].set_yticks([0, 20])\n",
    "            ax[iRow, iSide].set_title(rn_now, fontsize=14)            \n",
    "ax[iRow, iSide].set_xlim(x[0], x[-1])\n",
    "ax[iRow, iSide].set_xlabel('Time (s)')\n",
    "fh.suptitle('$Ca^{2+}$ responses to head and tail stim-elicited escapes ($\\mu \\pm CI$); R --> ipsi to stim')\n",
    "fh.subplots_adjust(hspace=0.15, top=0.96)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save the figure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDir = r'Y:\\Avinash\\Projects\\RS recruitment\\Figures'\n",
    "saveDir = os.path.join(figDir, util.timestamp())\n",
    "if not os.path.exists(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "fn = f'Fig-{util.timestamp()}_Ca responses in response to head- and tail stim-elicited escapes'\n",
    "fh.savefig(os.path.join(saveDir, fn + '.pdf'))\n",
    "fh.savefig(os.path.join(saveDir, fn + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Plot peak Ca2+ responses as factor plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Create a new dataframe suitable for categorical/factor plot\n",
    "nPre = 3\n",
    "sf = 2500\n",
    "roiNames_all = np.array(dataFrame.roiName)\n",
    "roiNames_core = np.array([_.split('.')[1] for _ in np.unique(roiNames_all)])\n",
    "roiNames_core = np.unique(roiNames_core)\n",
    "roiNames_core = roiNames_core[rsp.bing.omitRois(roiNames_core, ['LL'])]\n",
    "roi_dict = dict(ca_ts=[], roiName=[], stim=[], ca_pk=[], fishIdx=[], side=[], trlNum=[])\n",
    "for rn in roiNames_core:\n",
    "    for side in ['L', 'R']:\n",
    "        for stim in ['h', 't']:\n",
    "            rn_now = f'{side}.{rn}'    \n",
    "            inds = util.findStrInList(rn_now, roiNames_all)\n",
    "            if len(inds)==0:\n",
    "                print(f'No roi by that name: {rn_now}')\n",
    "            else:\n",
    "                df_sub = dataFrame.iloc[inds]\n",
    "                fishInds = np.unique(df_sub.fishIdx)\n",
    "                for iFish, idx_fish in enumerate(fishInds):\n",
    "                    df_fish = df_sub.loc[df_sub.fishIdx==idx_fish]\n",
    "                    ca_ = np.array([np.array(_) for _ in df_sub.loc[df_sub.stimLoc==stim].ca])\n",
    "                    f0 = np.median(ca_[:,:nPre], axis=1)[:, None]\n",
    "                    ca_ = ca_-f0\n",
    "                    pks = np.round((ca_.max(axis=1)*sf)*100)/100\n",
    "                    nTrls = len(pks)\n",
    "                    roi_dict['trlNum'].extend(np.arange(nTrls))\n",
    "                    roi_dict['ca_ts'].extend(ca_)\n",
    "                    roi_dict['roiName'].extend(np.array([rn]*nTrls))\n",
    "                    roi_dict['stim'].extend(np.array([stim.upper()]*nTrls))\n",
    "                    roi_dict['side'].extend(np.array([side.upper()]*nTrls))\n",
    "                    roi_dict['fishIdx'].extend(np.array([idx_fish]*nTrls))\n",
    "                    roi_dict['ca_pk'].extend(pks)                    \n",
    "dataFrame_max = pd.DataFrame(roi_dict)\n",
    "# print(np.unique(dataFrame.iloc[inds].path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=dataFrame_max, y='roiName', x='ca_pk', kind='point', hue='stim', \n",
    "                col='side', aspect=0.25, height=15, margin_titles=True, ci=99, palette='tab10', sharex=True)\n",
    "g.fig.suptitle(\"$Ca^{2+}$ response amplitudes for head and tail-elicited escapes; R --> ipsi to stim\")\n",
    "g.fig.subplots_adjust(top=0.92)\n",
    "g.set_xlabels('$Ca^{2+}$ response amplitude')\n",
    "fn = f'Fig-{util.timestamp()} Ca response amplitudes for head and tail-elicited stimuli'\n",
    "g.savefig(os.path.join(saveDir, fn + '.pdf'), dpi='figure')\n",
    "g.savefig(os.path.join(saveDir, fn + '.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=dataFrame_max, y='roiName', x='ca_pk', kind='point', hue='stim', \n",
    "                col='fishIdx', aspect=0.25, height=15, margin_titles=True, ci=99,\n",
    "                palette='tab10', sharex=True, row='side')\n",
    "g.fig.suptitle(\"$Ca^{2+}$ response amplitudes for head and tail-elicited escapes; R --> ipsi to stim\")\n",
    "g.fig.subplots_adjust(top=0.92)\n",
    "g.set_xlabels('$Ca^{2+}$ response amplitude')\n",
    "fn = f'Fig-{util.timestamp()} Ca response amplitudes for head and tail-elicited stimuli'\n",
    "# g.savefig(os.path.join(saveDir, fn + '.pdf'), dpi='figure')\n",
    "# g.savefig(os.path.join(saveDir, fn + '.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Behavior variability*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% A function for extracting behavior and stim location from paths and putting in dataframe\n",
    "def get_behav_from_path(path, fishLen=50):\n",
    "    path_hFile = glob.glob(os.path.join(path, 'procData*.h5'))\n",
    "    if len(path_hFile)>0:\n",
    "        path_hFile = path_hFile[-1]\n",
    "    else:\n",
    "        print(f'No HDF file in path:\\t {path}')\n",
    "        return None\n",
    "    with h5py.File(path_hFile, mode='r') as hFile:\n",
    "        if 'behav' in hFile:\n",
    "            grp = hFile['behav']\n",
    "            if ('tailAngles' in grp) & ('stimLoc' in grp):\n",
    "                ta = np.array(grp['tailAngles'])\n",
    "                nTrls = ta.shape[0]//fishLen\n",
    "                ta = ta[:nTrls*fishLen].reshape(nTrls, fishLen,-1)\n",
    "                stimLoc = util.to_utf(grp['stimLoc'])\n",
    "                trlNum = np.arange(nTrls)\n",
    "                dic = dict(trlNum=trlNum, tailAngles=list(ta), stim=stimLoc, path=[path_hFile]*nTrls)\n",
    "            else:\n",
    "                dic = None\n",
    "        else:\n",
    "            dic=None\n",
    "    if dic is not None:\n",
    "        dic = pd.DataFrame(dic)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Extract tail angles from all datasets where behavior's been extracted already_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishInds = np.unique(xls.FishIdx)\n",
    "dataFrame_behav = []\n",
    "for iFish, idx_fish in enumerate(fishInds):\n",
    "    print(f'Fish # {iFish}/{len(fishInds)}')\n",
    "    path_ = xls.loc[xls.FishIdx==idx_fish].Path.iloc[0]\n",
    "    df_ = get_behav_from_path(path_)\n",
    "    if df_ is not None:\n",
    "        df_ = df_.assign(fishIdx=idx_fish)\n",
    "        dataFrame_behav.append(df_)\n",
    "dataFrame_behav = pd.concat(dataFrame_behav, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Clean tail angles using SVD_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Clean tail angles using SVD\n",
    "trlLens = np.array([_.shape[-1] for _ in ta])\n",
    "trlLen = trlLens.min()\n",
    "ta = np.array([np.array(_)[:,:trlLen] for _ in np.array(dataFrame_behav.tailAngles)])\n",
    "nTrls = ta.shape[0]\n",
    "ta_ser = np.concatenate(ta, axis=1)\n",
    "# Clean tailAngles\n",
    "%time ta_clean, _, svd = hf.cleanTailAngles(ta_ser)\n",
    "ta_trl = np.array(np.hsplit(ta_clean, nTrls))\n",
    "dataFrame_behav = dataFrame_behav.assign(tailAngles = list(ta_clean_trl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Load pre-trained GM model and predict on all the behavrior trials_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Load the trained model\n",
    "import joblib\n",
    "dir_group = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\GCaMP imaging\\Group'\n",
    "file_model = 'gmm_svd-3_env_pca-9_gmm-20_20200418-11.pkl' \n",
    "gmm_model = joblib.load(os.path.join(dir_group, file_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsb.copy_images_for_training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = []\n",
    "for ta_ in ta_trl:\n",
    "    lbls = gmm_model.predict(ta_)[0]\n",
    "    labels.append(lbls)\n",
    "dataFrame_behav = dataFrame_behav.assign(gmmLabels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls_of_interest = [18, 14, 1, 6, 11, 19, 15, 8]\n",
    "lbl_names = ['Fast-large_struggle', 'Fast-large-escape', 'Medium slow',\n",
    "             'Medium slow', 'Medium slow', 'Slow', 'Slow', 'Flicks']\n",
    "tKer = 50e-3\n",
    "\n",
    "labels=np.array(labels)\n",
    "likelihood_swim = np.log2(np.abs(ta[:,-1,:]).mean(axis=0))\n",
    "impulses_lbls = []\n",
    "for lbl in lbls_of_interest:\n",
    "    foo = np.zeros_like(labels)\n",
    "    foo[np.where(labels==lbl)]=1\n",
    "    impulses_lbls.append(foo)\n",
    "impulses_lbls = np.array(impulses_lbls)\n",
    "stimLoc = np.array(dataFrame_behav.stim)\n",
    "trls_head = np.where(stimLoc=='h')[0]\n",
    "trls_tail = np.where(stimLoc=='t')[0]\n",
    "\n",
    "impulses_lbls_head = impulses_lbls[:, trls_head]\n",
    "impulses_lbls_tail = impulses_lbls[:, trls_tail]\n",
    "foo_head = impulses_lbls_head.sum(axis=1)\n",
    "foo_tail = impulses_lbls_tail.sum(axis=1)\n",
    "nKer = int(tKer*500)\n",
    "P_head, P_tail = [], [] \n",
    "for lbl in foo_head:\n",
    "    lbl_conv = spt.causalConvWithSemiGauss1d(lbl, nKer)\n",
    "    P_head.append(lbl_conv)\n",
    "    \n",
    "for lbl in foo_tail:\n",
    "    lbl_conv = spt.causalConvWithSemiGauss1d(lbl, nKer)\n",
    "    P_tail.append(lbl_conv)\n",
    "\n",
    "P_head, P_tail = np.array(P_head), np.array(P_tail)\n",
    "tot = P_head.sum() + P_tail.sum()\n",
    "P_head /= trls_head.shape[0]\n",
    "P_tail /= trls_tail.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(likelihood_swim)\n",
    "plt.xlim(0, len(likelihood_swim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(P_head.shape[1])*(1/500)*1000\n",
    "fh, ax = plt.subplots(P_head.shape[0],1, figsize=(20, 20), sharex=True, sharey=True)\n",
    "count = 0\n",
    "for head, tail in zip(P_head, P_tail):\n",
    "#     ax[count].plot(x, np.log2(head+1e-6), c=plt.cm.tab10(0))\n",
    "#     ax[count].plot(x, np.log2(tail+1e-6), c=plt.cm.tab10(1))\n",
    "    ax[count].plot(x, head, c=plt.cm.tab10(2))\n",
    "    ax[count].plot(x, tail, c=plt.cm.tab10(3))\n",
    "#     ax[count].set_ylabel(f'Label # {lbls_of_interest[count]}')\n",
    "    ax[count].set_ylabel(f'{lbl_names[count]}', rotation=45)\n",
    "    count +=1\n",
    "ax[count-1].set_xlim(800, 3000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
