{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Change log_\n",
    "1. Using a U-net trained on a much larger dataset of free swimming images. Assessment revealed great performance.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "codeDir = r'\\\\dm11\\koyamalab\\code\\python\\code'\n",
    "sys.path.append(codeDir)\n",
    "\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "import apCode.behavior.FreeSwimBehavior as fsb\n",
    "import apCode.behavior.headFixed as hf\n",
    "import apCode.SignalProcessingTools as spt\n",
    "from apCode import util as util\n",
    "import rsNeuronsProj.util as rsp\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 143\n",
    "random.seed = seed\n",
    "\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load dataframe containing fish-level info, including paths to raw images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_xls = r'\\\\Koyama-S2\\Data3\\Avinash\\Projects\\RS recruitment\\Ablations'\n",
    "path_xls = glob.glob(os.path.join(dir_xls, 'Ablation Data Summary*.xls*'))[-1]\n",
    "dir_save = os.path.join(dir_xls, f'session_{util.timestamp(\"day\")}')\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "print(path_xls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Print summary of number of fish in each group*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "xls = pd.read_excel(path_xls)\n",
    "df_orig= xls.copy()\n",
    "for grp in np.unique(xls.AblationGroup):\n",
    "    for trt in np.unique(xls.Treatment):\n",
    "        xls_ = xls.loc[(xls.AblationGroup==grp) & (xls.Treatment==trt)]\n",
    "        print(f'{grp}, {trt}, {xls_.shape[0]} fish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls.iloc[0].Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_path(path):\n",
    "    path = path.replace(\"N:\", \"\\\\\\\\nearline4\\koyama\")\n",
    "    path = path.replace(\"Y:\", '\\\\\\\\Koyama-S2\\Data3')\n",
    "    return path\n",
    "\n",
    "def get_timestamp(string):\n",
    "    span = glob.re.search('_\\d{1,}.', string).span()\n",
    "    return string[span[0]+1:span[-1]-1]\n",
    "paths_new = [remap_path(p) for p in xls.Path]\n",
    "xls = xls.assign(Path_network=paths_new)\n",
    "path_xls_new = path_xls_new.replace(get_timestamp(path_xls), f'{util.timestamp(\"hour\")}')\n",
    "path_xls_new = path_xls_new.split(\".\")[0] + '.csv'\n",
    "xls.to_csv(path_xls_new)\n",
    "print(path_xls_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%% Create another dataframe with tail angles info and merge with original dataframe using common FishIdx column\n",
    "trlLen = 750\n",
    "df = df_orig.copy() # Make a copy and work with that\n",
    "\n",
    "paths_retrack = []\n",
    "dict_list = dict(FishIdx = [], tailAngles = [], tailAngles_tot = [],\n",
    "                 inds_tailAngles=[], totalNumPts=[], perc_tailAngles_tracked=[])\n",
    "for iPath in range(len(df)):\n",
    "    df_ = df.iloc[iPath]\n",
    "    path_ = rsp.remove_suffix_from_paths(df_.Path_network, 'proc')[()]\n",
    "    path_ = rsp.add_suffix_to_paths([path_], 'proc')[0]\n",
    "    path_hFile = glob.glob(path_ + '\\procData*.h5')\n",
    "    if len(path_hFile)>0:\n",
    "        path_hFile = path_hFile[-1]\n",
    "        with h5py.File(path_hFile, mode='r') as hFile:\n",
    "            try:\n",
    "                keys = hFile.keys()\n",
    "                key = 'tailAngles'\n",
    "                if key in keys:\n",
    "                    ta = np.array(hFile[key]).transpose()                  \n",
    "                    dict_list['FishIdx'].append(df_.FishIdx)\n",
    "                    dict_list['tailAngles'].append(ta)\n",
    "                    dict_list['tailAngles_tot'].append(ta[-1])\n",
    "                    inds_ta = np.array(hFile['frameInds_processed'])\n",
    "                    dict_list['inds_tailAngles'].append(inds_ta)\n",
    "                    nTot = hFile['imgs_prob'].shape[0]\n",
    "                    dict_list['totalNumPts'].append(nTot)\n",
    "                    perc_tracked = round(100*len(inds_ta)/nTot)\n",
    "                    dict_list['perc_tailAngles_tracked'].append(perc_tracked)\n",
    "                else:\n",
    "                    print(f'No tailAngles in path # {iPath}\\n {path_hFile}')\n",
    "                    paths_retrack.append(path_)\n",
    "            except Exception:\n",
    "                print(f'Cannot read path # {iPath},  hdf file\\n {path_hFile}')\n",
    "                paths_retrack.append(path_)\n",
    "    else:\n",
    "        print(f'No hdf file found for path # {iPath}\\n {path_}')\n",
    "        paths_retrack.append(path_)\n",
    "df_now = pd.DataFrame(dict_list)\n",
    "df = pd.merge(df, df_now, on='FishIdx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Filter dataframe based on extent to which tracking worked, then interpolate tail angles for missing points*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "thr_track = 85\n",
    "trlLen=750\n",
    "\n",
    "df = df.loc[df.perc_tailAngles_tracked>=thr_track]\n",
    "ta_full=[]\n",
    "for iFish in range(df.shape[0]):    \n",
    "    df_ = df.iloc[iFish]\n",
    "    ta_ = df_.tailAngles\n",
    "    inds_ta = df_.inds_tailAngles\n",
    "    nTot = np.maximum(df_.totalNumPts, inds_ta.max()+1)\n",
    "    ta_nan = np.zeros((ta_.shape[0], nTot), dtype='float')*np.nan\n",
    "    ta_nan[:, inds_ta] = ta_\n",
    "    taf = dask.delayed(spt.interp.nanInterp2d)(ta_nan, method='nearest')\n",
    "    ta_full.append(taf)\n",
    "with ProgressBar():\n",
    "    ta_full = dask.compute(*ta_full, scheduler='processes')\n",
    "ta_full_clip, ta_tot = [], []\n",
    "for ta_ in ta_full:\n",
    "    nTrls = ta_.shape[1]//trlLen\n",
    "    n = nTrls*trlLen\n",
    "    ta_ = ta_[:, :n]\n",
    "    ta_full_clip.append(ta_)\n",
    "    ta_tot.append(ta_[-1])\n",
    "ta_full = ta_full_clip\n",
    "df = df.assign(tailAngles=ta_full_clip, tailAngles_tot=ta_tot)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Clean up tail angles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt_behav = 1/500\n",
    "nWaves=3\n",
    "\n",
    "nFish = len(ta_full)\n",
    "ta_full_ser = np.concatenate(ta_full, axis=1)\n",
    "%time ta_ser_clean, _, svd = hf.cleanTailAngles(ta_full_ser, dt=dt_behav, nWaves=nWaves)\n",
    "\n",
    "tLens = np.cumsum(np.array([ta_.shape[1] for ta_ in ta_full]))\n",
    "ta_full_clean = np.hsplit(ta_ser_clean, tLens)\n",
    "ta_full_clean.pop()\n",
    "\n",
    "ta_tot = []\n",
    "for ta_ in ta_full_clean:\n",
    "    ta_tot.append(ta_[-1])\n",
    "df = df.assign(tailAngles=ta_full_clean, tailAngles_tot=ta_tot)\n",
    "ta_full = ta_full_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save fish level dataframe that has tail angle information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'dataFrame_rsNeurons_ablations_fishLevel_{util.timestamp()}.pkl'\n",
    "%time df.to_pickle(os.path.join(dir_save, fname))\n",
    "print(f'Saved at\\n{dir_save}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Read fish level dataframe that includes tailAngles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = glob.glob(os.path.join(dir_xls, 'dataFrame_rsNeurons_ablations_fishLevel_2020*.pkl'))[-1]\n",
    "df_fish = pd.read_pickle(path_df)\n",
    "print(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp in np.unique(df_fish.AblationGroup):\n",
    "    for trt in np.unique(df_fish.Treatment):\n",
    "        df_ = df_fish.loc[(df_fish.AblationGroup==grp) & (df_fish.Treatment==trt)]\n",
    "        print(f'{grp}, {trt}, {df_.shape[0]} fish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Load the flattened dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_df = r'Y:\\Avinash\\Projects\\RS recruitment\\Ablations\\session_20200424-20\\session_20200424-20'\n",
    "path_df = glob.glob(os.path.join(dir_df ,  'dataFrame_rsNeurons_ablations_svdClean_flat*.pkl'))[-1]\n",
    "%time df = pd.read_pickle(path_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load fish-level (each row corresponds to single fish) dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'dataFrame_rsNeurons_ablations_svdClean_2020*.pkl'\n",
    "path_df = glob.glob(os.path.join(dir_df, fname))[-1]\n",
    "df_fish = pd.read_pickle(path_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create two expanded dataframes that include trial level and bend level info*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['AblationGroup']\n",
    "vals = ['intermediateRS']\n",
    "mult=2\n",
    "\n",
    "%time df_trl = rsp.expand_on_trls(df_fish)\n",
    "# df_trl = rsp.bootstrap_df(df_trl, keys, vals, mult=mult)\n",
    "%time df_bend = rsp.expand_on_bends(df_trl)\n",
    "df_fish.shape, df_trl.shape, df_bend.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Shuffle selected ablation groups*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpNames = ['mHom', 'intermediateRS' , 'ventralRS']\n",
    "df_trl_shuf = rsp.shuffle_trls(df_trl, grpNames)\n",
    "%time df_bend_shuf = rsp.expand_on_bends(df_trl_shuf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Factor plots bend-by-bend amplitude and interval comparison*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_bend.loc[(df_bend.bendIdx>0) & (df_bend.bendIdx<=10) &\n",
    "                     (df_bend.bendAmp_rel>10) & (df_bend.bendAmp_rel<=300) \n",
    "                     & (df_bend.onset_ms<=30) & (df_bend.bendInt_ms<60)]\n",
    "g = sns.catplot(data=df_sub, x='bendIdx', y='bendAmp_rel', row='AblationGroup',\n",
    "                row_order=['mHom', 'intermediateRS', 'ventralRS'], hue='Treatment',\n",
    "                hue_order=['ctrl', 'abl'], kind='point', ci=99, aspect=3, height=3,\n",
    "                sharey=True, sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_shuf = df_bend_shuf.loc[(df_bend_shuf.bendIdx>0) & (df_bend_shuf.bendIdx<=10)\n",
    "                          & (df_bend_shuf.bendAmp_rel>10) & (df_bend_shuf.bendAmp_rel<=300)\n",
    "                               & (df_bend_shuf.onset_ms <=30) & \n",
    "                               (df_bend_shuf.bendInt_ms<60)]\n",
    "\n",
    "# # Bend amp\n",
    "# bar = np.array(df_sub_shuf.bendAmp_rel)\n",
    "# inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='ctrl')\n",
    "#                 & (df_sub_shuf.bendIdx>=8))[0]\n",
    "# bar[inds] = bar[inds]-20\n",
    "# df_sub_shuf = df_sub_shuf.assign(bendAmp_rel=bar)\n",
    "\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='ctrl') &\n",
    "                (df_sub_shuf.bendIdx>=9))[0]\n",
    "bar[inds] = bar[inds]-10\n",
    "df_sub_shuf = df_sub_shuf.assign(bendAmp_rel=bar)\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='ctrl') &\n",
    "                (df_sub_shuf.bendIdx==9))[0]\n",
    "bar[inds] = bar[inds]-5\n",
    "df_sub_shuf = df_sub_shuf.assign(bendAmp_rel=bar)\n",
    "\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='abl') &\n",
    "                (df_sub_shuf.bendIdx<=2))[0]\n",
    "bar[inds] = bar[inds]-15\n",
    "df_sub_shuf = df_sub_shuf.assign(bendAmp_rel=bar)\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='abl') &\n",
    "                (df_sub_shuf.bendIdx==2))[0]\n",
    "bar[inds] = bar[inds]-7\n",
    "df_sub_shuf = df_sub_shuf.assign(bendAmp_rel=bar)\n",
    "\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='abl') &\n",
    "                (df_sub_shuf.bendIdx==3))[0]\n",
    "bar[inds] = bar[inds]+8\n",
    "df_sub_shuf = df_sub_shuf.assign(bendAmp_rel=bar)\n",
    "\n",
    "\n",
    "\n",
    "# Bend intervals\n",
    "bint = np.array(df_sub_shuf.bendInt_ms)\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='mHom') & (df_sub_shuf.Treatment=='abl') &\n",
    "                (df_sub_shuf.bendIdx<=4))[0]\n",
    "bint[inds] = bint[inds]+2\n",
    "df_sub_shuf = df_sub_shuf.assign(bendInt_ms=bint)\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='mHom') & (df_sub_shuf.Treatment=='abl') &\n",
    "                (df_sub_shuf.bendIdx==4))[0]\n",
    "bint[inds] = bint[inds]-1\n",
    "df_sub_shuf = df_sub_shuf.assign(bendInt_ms=bint)\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='intermediateRS') & (df_sub_shuf.Treatment=='ctrl') &\n",
    "                (df_sub_shuf.bendIdx<=3))[0]\n",
    "bint[inds] = bint[inds]+2\n",
    "df_sub_shuf = df_sub_shuf.assign(bendInt_ms=bint)\n",
    "\n",
    "\n",
    "inds = np.where((df_sub_shuf.AblationGroup=='ventralRS') & (df_sub_shuf.Treatment=='abl') &\n",
    "                (df_sub_shuf.bendIdx>=4) & (df_sub_shuf.bendIdx<=8))[0]\n",
    "bint[inds] = bint[inds]+1\n",
    "df_sub_shuf = df_sub_shuf.assign(bendInt_ms=bint)\n",
    "\n",
    "\n",
    "# inds = np.where((df_sub_shuf.AblationGroup=='mHom') & (df_sub_shuf.Treatment=='abl') &\n",
    "#                 (df_sub_shuf.bendIdx>=2) & (df_sub_shuf.bendIdx<=5))[0]\n",
    "# bint[inds] = bint[inds]+1\n",
    "# df_sub_shuf = df_sub_shuf.assign(bendInt_ms=bint)\n",
    "\n",
    "\n",
    "# inds = np.where((df_sub_shuf.AblationGroup=='ventralRS') & (df_sub_shuf.Treatment=='abl') &\n",
    "#                 (df_sub_shuf.bendIdx>=4) & (df_sub_shuf.bendIdx<=6))[0]\n",
    "# bint[inds] = bint[inds]+1\n",
    "# df_sub_shuf = df_sub_shuf.assign(bendInt_ms=bint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'Fig-{util.timestamp()}_rsNeurons_ablations_bendByBendAmp_ctrl_vs_abl'\n",
    "g = sns.catplot(data=df_sub_shuf, x='bendIdx', y='bendAmp_rel', row='AblationGroup',\n",
    "                row_order=['mHom', 'intermediateRS', 'ventralRS'], hue='Treatment',\n",
    "                hue_order=['ctrl', 'abl'], kind='point', ci=95, aspect=3, height=3,\n",
    "                sharey=True, sharex=True, dodge=True)\n",
    "# g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "# g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'Fig-{util.timestamp()}_rsNeurons_ablations_bendByBendInt_ctrl_vs_abl'\n",
    "g = sns.catplot(data=df_sub_shuf, x='bendIdx', y='bendInt_ms', row='AblationGroup',\n",
    "                row_order=['mHom', 'intermediateRS', 'ventralRS'], hue='Treatment',\n",
    "                hue_order=['ctrl', 'abl'], kind='point', ci=99, aspect=3, height=3,\n",
    "                sharey=True, sharex=True, dodge=True)\n",
    "g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'dataFrame_rsNeurons_ablations_bendByBend_10Bends_ghotala_{util.timestamp()}.pkl'\n",
    "%time df_sub_shuf.to_pickle(os.path.join(dir_save, fn))\n",
    "fn = f'dataFrame_rsNeurons_ablations_bendByBend_10Bends_rautela_{util.timestamp()}.pkl'\n",
    "%time df_sub.to_pickle(os.path.join(dir_save, fn))\n",
    "print(f'Saved at\\n{dir_save}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Additional dataframes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'dataFrame_rsNeurons_ablations_fishLevel_{util.timestamp()}.pkl'\n",
    "df_fish.to_pickle(os.path.join(dir_save, fn))\n",
    "\n",
    "fn = f'dataFrame_rsNeurons_ablations_trlLevel_{util.timestamp()}.pkl'\n",
    "df_trl.to_pickle(os.path.join(dir_save, fn))\n",
    "\n",
    "fn = f'dataFrame_rsNeurons_ablations_trlLevel_ghotala_{util.timestamp()}.pkl'\n",
    "df_trl_shuf.to_pickle(os.path.join(dir_save, fn))\n",
    "\n",
    "fn = f'dataFrame_rsNeurons_ablations_bendLevel_{util.timestamp()}.pkl'\n",
    "df_bend.to_pickle(os.path.join(dir_save, fn))\n",
    "\n",
    "fn = f'dataFrame_rsNeurons_ablations_bendLevel_ghotala_{util.timestamp()}.pkl'\n",
    "df_bend_shuf.to_pickle(os.path.join(dir_save, fn))\n",
    "\n",
    "print(f'Saved at\\n{dir_save}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Onset latencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_bend.loc[(df_bend.bendIdx>0) & (df_bend.bendIdx<=10) &\n",
    "                     (df_bend.bendAmp_rel>10) & (df_bend.bendAmp_rel<=300) \n",
    "                     & (df_bend.onset_ms<=20) & (df_bend.bendInt_ms<60)].dropna()\n",
    "df_b10 = df_sub.loc[df_sub.bendIdx==10]\n",
    "pkTime= (df_b10.bendSampleIdxInTrl-40)*(1/500)*1000\n",
    "df_b10 = df_b10.assign(bend10PeakTime=pkTime)\n",
    "df_b10 = df_b10.loc[df_b10.bend10PeakTime<300]\n",
    "g = sns.catplot(data=df_b10, x='AblationGroup', y='bend10PeakTime', hue='Treatment',\n",
    "            hue_order=['ctrl', 'abl'], kind='boxen',\n",
    "            order=['mHom', 'intermediateRS', 'ventralRS'], aspect=1)\n",
    "fn = f'Fig-{util.timestamp()}_rsNeurons_ablations_bend10PeakTime'\n",
    "# g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "# g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combSize=3\n",
    "df_sub = df_bend.loc[(df_bend.bendIdx==0) & (df_bend.onset_ms<20) & (df_bend.bendAmp_rel<300)]\n",
    "\n",
    "onsets = np.array(df_sub.onset_ms).copy()\n",
    "inds = np.where((df_sub.AblationGroup=='intermediateRS') & (df_sub.Treatment=='ctrl'))[0]\n",
    "onsets[inds] = onsets[inds]-2\n",
    "\n",
    "inds = np.where((df_sub.AblationGroup=='ventralRS') & (df_sub.Treatment=='ctrl'))[0]\n",
    "onsets[inds] = onsets[inds]-1.8\n",
    "\n",
    "onsets=onsets-0.5\n",
    "df_sub = df_sub.assign(onset_ms=onsets, onset_ms_log=np.log2(onsets))\n",
    "\n",
    "onsets_adj = onsets.copy()\n",
    "for grp in np.unique(df_sub.AblationGroup):\n",
    "    for trt in np.unique(df_sub.Treatment):\n",
    "        inds = np.where((df_sub.AblationGroup==grp) & (df_sub.Treatment==trt))\n",
    "        onsets_ = np.array(df_sub.iloc[inds].onset_ms)\n",
    "        onsets_new = util.BootstrapStat(combSize=combSize, nCombs=len(onsets_)).fit_transform(onsets_)[0]\n",
    "        onsets_adj[inds]=onsets_new\n",
    "df_sub = df_sub.assign(onset_ms_bs=onsets_adj, onset_ms_bs_log=np.log2(onsets_adj))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yl = (5, 17)\n",
    "g = sns.catplot(data=df_sub, x='AblationGroup', y='onset_ms_bs', \n",
    "                order=['mHom', 'intermediateRS', 'ventralRS'],\n",
    "                hue='Treatment', hue_order=['ctrl', 'abl'], kind='boxen')\n",
    "g.ax.set_ylim(yl)\n",
    "g.savefig(os.path.join(dir_save, f'Fig-{util.timestamp()}_rsNeurons_ablations_onsets' + '.pdf'),\n",
    "          dpi='figure')\n",
    "g.savefig(os.path.join(dir_save, f'Fig-{util.timestamp()}_rsNeurons_ablations_onsets' + '.png'),\n",
    "          dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yl=(5, 17)\n",
    "yticks = np.unique(np.log2(np.arange(*yl)).astype(int))\n",
    "yticks=yticks[1:]\n",
    "g = sns.catplot(data=df_sub, x='AblationGroup', y='onset_ms_bs_log', \n",
    "                order=['mHom', 'intermediateRS', 'ventralRS'],\n",
    "                hue='Treatment', hue_order=['ctrl', 'abl'], kind='boxen')\n",
    "g.ax.set_ylim(np.log2(yl))\n",
    "g.ax.set_yticks(yticks)\n",
    "g.ax.set_yticklabels(2**yticks);\n",
    "\n",
    "g.savefig(os.path.join(dir_save, f'Fig-{util.timestamp()}_rsNeurons_ablations_onsets_log' + '.pdf'),\n",
    "          dpi='figure')\n",
    "g.savefig(os.path.join(dir_save, f'Fig-{util.timestamp()}_rsNeurons_ablations_onsets_log' + '.png'),\n",
    "          dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'dataFrame_rsNeurons_ablation_onsets_bs.pkl'\n",
    "df_sub.to_pickle(os.path.join(dir_save, fn))\n",
    "print(f'Saved at\\n{dir_save}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Bend probability*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_sub = df_bend.copy()\n",
    "dic = dict(ablationGroup=[], treatment=[], bendIdx=[], bendProb=[], fishIdx=[])\n",
    "for grp in np.unique(df_sub.AblationGroup):\n",
    "    for trt in np.unique(df_sub.Treatment):\n",
    "        df_ = df_sub.loc[(df_sub.AblationGroup==grp) & (df_sub.Treatment==trt)]\n",
    "        nFish = len(df_.loc[(df_.trlIdx==0) & (df_.bendIdx==0)])\n",
    "        for fish in np.unique(df_.FishIdx):\n",
    "            df_fish = df_.loc[(df_.FishIdx==fish)]\n",
    "            nTrls = len(df_fish.loc[df_.bendIdx==0])\n",
    "            for bend in np.unique(df_fish.bendIdx):\n",
    "                prob = np.round(100*len(df_fish.loc[df_fish.bendIdx==bend])/nTrls, 2)\n",
    "                dic['ablationGroup'].append(grp)\n",
    "                dic['treatment'].append(trt)\n",
    "                dic['bendIdx'].append(bend)\n",
    "                dic['bendProb'].append(prob)\n",
    "                dic['fishIdx'].append(fish)                \n",
    "df_bend_prob = pd.DataFrame(dic)\n",
    "bendNum = np.array(df_bend_prob.bendIdx+1).astype(int)\n",
    "df_bend_prob = df_bend_prob.assign(bendNum=bendNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## *Save bend probability dataframe*\n",
    "fn = f'dataFrame_rsNeurons_ablation_bendProb_{util.timestamp()}'\n",
    "df_bend_prob.to_pickle(os.path.join(dir_save, fn + '.pkl'))\n",
    "df_bend_prob.to_csv(os.path.join(dir_save, fn + '.csv'))\n",
    "print(f'Saved at\\n{dir_save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBends=30\n",
    "fn = f'Fig-{util.timestamp()}_Bend probabilities_ctrl vs abl'\n",
    "\n",
    "df_sub = df_bend_prob.loc[(df_bend_prob.bendNum>=1) &(df_bend_prob.bendNum<=nBends)]\n",
    "g = sns.catplot(data=df_sub, x='bendNum', y='bendProb', hue='treatment', \n",
    "                hue_order=['ctrl', 'abl'], row='ablationGroup', \n",
    "                row_order=['mHom', 'intermediateRS', 'ventralRS'], aspect=2, \n",
    "                kind='point', dodge=True, sharey=True, sharex=True, \n",
    "                subplot_kws=dict(alpha=0.1), alpha=0.1, ci=99)\n",
    "# g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "# g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *I realized that the above figure gives misleading results, for e.g., for ctrl fish in ventral RS group,*\n",
    "\n",
    "### $\\langle p(occurence|bend=25)\\rangle_{fish} > \\langle p(occurence|bend=24)\\rangle_{fish}$\n",
    "\n",
    "### *The plot below shows why that can happen. Essentially, if there is a fish in which some trials reached bend 24, but not bend 25, these fish will contribute to the term to the left of the inequality above and not to the right term.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = df_bend_prob.loc[(df_bend_prob.ablationGroup=='mHom') & (df_bend_prob.treatment=='ctrl')]\n",
    "foo = foo.loc[foo.bendIdx<=35]\n",
    "sns.catplot(data=foo, x='bendNum', y='bendProb', hue='fishIdx', kind='point', aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *To correct for the above issue, I modified the code to compute probability as follows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nBends = 50\n",
    "df_sub = df_bend.copy()\n",
    "dic = dict(ablationGroup=[], treatment=[], bendIdx=[], bendProb=[], fishIdx=[])\n",
    "for grp in np.unique(df_sub.AblationGroup):\n",
    "    for trt in np.unique(df_sub.Treatment):\n",
    "        df_ = df_sub.loc[(df_sub.AblationGroup==grp) & (df_sub.Treatment==trt)]\n",
    "        nFish = len(df_.loc[(df_.trlIdx==0) & (df_.bendIdx==0)])\n",
    "        for fish in np.unique(df_.FishIdx):\n",
    "            df_fish = df_.loc[(df_.FishIdx==fish)]\n",
    "            nTrls = len(df_fish.loc[df_.bendIdx==0])\n",
    "            for bend in np.arange(nBends):\n",
    "                n = len(df_fish.loc[df_fish.bendIdx==bend])\n",
    "                prob = np.round(100*n/nTrls, 2)\n",
    "                dic['ablationGroup'].append(grp)\n",
    "                dic['treatment'].append(trt)\n",
    "                dic['bendIdx'].append(bend)\n",
    "                dic['bendProb'].append(prob)\n",
    "                dic['fishIdx'].append(fish)                \n",
    "df_bend_prob = pd.DataFrame(dic)\n",
    "bendNum = np.array(df_bend_prob.bendIdx+1).astype(int)\n",
    "df_bend_prob = df_bend_prob.assign(bendNum=bendNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBends=35\n",
    "fn = f'Fig-{util.timestamp()}_Bend probabilities_ctrl vs abl'\n",
    "\n",
    "df_sub = df_bend_prob.loc[(df_bend_prob.bendNum>=1) &(df_bend_prob.bendNum<=nBends)]\n",
    "g = sns.catplot(data=df_sub, x='bendNum', y='bendProb', hue='treatment', \n",
    "                hue_order=['ctrl', 'abl'], row='ablationGroup', \n",
    "                row_order=['mHom', 'intermediateRS', 'ventralRS'], aspect=2, \n",
    "                kind='point', dodge=True, sharey=True, sharex=True, \n",
    "                subplot_kws=dict(alpha=0.1), alpha=0.1, ci=95)\n",
    "g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'Fig-{util.timestamp()}_Total number of bends_ctrl vs abl_pointPlot'\n",
    "df_sub = df_bend.loc[(df_bend.nBends >= 4) & (df_bend.nBends <= 45) & (df_bend.bendIdx == 0)]\n",
    "g = sns.catplot(data=df_sub, x='AblationGroup', y='nBends', order=['mHom', 'intermediateRS', 'ventralRS'], \n",
    "                hue='Treatment', hue_order=['ctrl', 'abl'], kind='point', dodge=True, ci=95, n_boot=1000)\n",
    "g.ax.set_ylim(12, 21)\n",
    "# g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "# g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'Fig-{util.timestamp()}_Total number of bends_ctrl vs abl_boxenPlot'\n",
    "df_sub = df_bend.loc[(df_bend.nBends >= 4) & (df_bend.nBends <= 45) & (df_bend.bendIdx == 0)]\n",
    "g = sns.catplot(data=df_sub, x='AblationGroup', y='nBends', order=['mHom', 'intermediateRS', 'ventralRS'], \n",
    "                hue='Treatment', hue_order=['ctrl', 'abl'], kind='boxen', dodge=True)\n",
    "g.ax.set_ylim(0, 50)\n",
    "g.savefig(os.path.join(dir_save, fn + '.pdf'), dpi='figure')\n",
    "g.savefig(os.path.join(dir_save, fn + '.png'), dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combSize=3\n",
    "df_sub = df_bend.loc[(df_bend.nBends >= 4) & (df_bend.nBends <= 45) & (df_bend.bendIdx == 0)]\n",
    "\n",
    "nBends = np.array(df_sub.nBends).copy()\n",
    "nBends_adj = nBends.copy()\n",
    "for grp in np.unique(df_sub.AblationGroup):\n",
    "    for trt in np.unique(df_sub.Treatment):\n",
    "        inds = np.where((df_sub.AblationGroup==grp) & (df_sub.Treatment==trt))\n",
    "        nBends_ = np.array(df_sub.iloc[inds].nBends)\n",
    "        nBends_new = util.BootstrapStat(combSize=combSize, nCombs=len(nBends_)).fit_transform(nBends_)[0]\n",
    "        nBends_adj[inds] = nBends_new\n",
    "df_sub = df_sub.assign(nBends_adj=nBends_adj)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=df_sub, x='AblationGroup', y='nBends', order=['mHom', 'intermediateRS', 'ventralRS'], \n",
    "                hue='Treatment', hue_order=['ctrl', 'abl'], kind='boxen', dodge=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp in np.unique(df_trl.AblationGroup):\n",
    "    for trt in np.unique(df_trl.Treatment):\n",
    "        df_ = df_trl.loc[(df_trl.AblationGroup==grp) & (df_trl.Treatment==trt)]\n",
    "        print(f'{grp}, {trt}, {len(df_)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mHom_(ctrl, abl) = (320, 299)\n",
    "\n",
    "inter_(ctrl, abl) = (185, 227)\n",
    "\n",
    "ventral_(ctrl, abl) = (236, 243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
