{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import relevant code\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import dask\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import models\n",
    "from skimage.util import montage\n",
    "import glob\n",
    "\n",
    "#--- Import my code\n",
    "codeDir = r'V:/code/python/code'\n",
    "sys.path.append(codeDir)\n",
    "import apCode.FileTools as ft\n",
    "import apCode.volTools as volt\n",
    "from apCode.machineLearning import ml as mlearn\n",
    "import apCode.SignalProcessingTools as spt\n",
    "from apCode.machineLearning.unet import model\n",
    "from apCode.behavior import FreeSwimBehavior as fsb\n",
    "from apCode import geom\n",
    "import apCode.hdf as hdf\n",
    "from apCode import util\n",
    "from rsNeuronsProj import util as rsp\n",
    "import apCode.behavior.headFixed as hf\n",
    "\n",
    "#--- Setting seed for reproducability\n",
    "seed = 143\n",
    "np.random.seed = seed\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "#--- Auto-reload modules\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(time.ctime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Load 2 U nets, one trained only on free swim diffuse light data and one trained on all types including head fixed and collimated light conditions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_unet = r'Y:\\Avinash\\Ablations and Behavior'\n",
    "learning_rate = 'default'\n",
    "\n",
    "path_unet_fsb = glob.glob(os.path.join(dir_unet, 'trainedU_fsb_896*.h5'))[-1]\n",
    "path_unet_all = glob.glob(os.path.join(dir_unet, 'trainedU_fsb_collimated_headFixed_*.h5'))[-1]\n",
    "\n",
    "print(path_unet_fsb + '\\n' + path_unet_all)\n",
    "unet_fsb = mlearn.loadPreTrainedUnet(path_unet_fsb) # Load pre-trained \n",
    "unet_all = mlearn.loadPreTrainedUnet(path_unet_all) # Load pre-trained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Read dataframe with all relevant information (paths, etc)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Path to excel sheet storing paths to data and other relevant info\n",
    "dir_df = r'Y:\\Avinash\\Projects\\RS recruitment\\Ablations\\session_20200422-00'\n",
    "path_df = glob.glob(os.path.join(dir_df, 'dataFrame_rsNeurons_ablations_svdClean_2020*.pkl'))[-1]\n",
    "\n",
    "df = pd.read_pickle(path_df)\n",
    "dir_save = os.path.join(dir_df, f'session_{util.timestamp()}')\n",
    "os.makedirs(dir_save, exist_ok=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Evaluate pre-training performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_all = [np.array(ta_) for ta_ in df['tailAngles']]\n",
    "ta_all = np.concatenate(ta_all, axis=1)\n",
    "%time _, _, svd = hf.cleanTailAngles(ta_all, dt=1/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctrl.shape, df_abl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iFish = (2, 2)\n",
    "iTrl = (2, 4)\n",
    "trlLen=750\n",
    "ablGrp = 'mHom'  # ['mHom', 'intermediateRS', 'ventralRS']\n",
    "\n",
    "plt.style.use(('seaborn-white', 'seaborn-ticks', 'fivethirtyeight', 'seaborn-talk'))\n",
    "\n",
    "df_ctrl = df.loc[(df.AblationGroup==ablGrp) & (df.Treatment=='ctrl')]\n",
    "df_abl = df.loc[(df.AblationGroup==ablGrp) & (df.Treatment=='abl')]\n",
    "\n",
    "ctrl = df_ctrl.loc[df_ctrl.FishIdx == df_ctrl.FishIdx.iloc[iFish[0]]]\n",
    "abl = df_abl.loc[df_abl.FishIdx == df_abl.FishIdx.iloc[iFish[1]]]\n",
    "\n",
    "ta_ctrl = np.array(ctrl['tailAngles'].iloc[0])\n",
    "ta_abl = np.array(abl['tailAngles'].iloc[0])\n",
    "\n",
    "r_ctrl = fsb.track.assessTracking(ta_ctrl)\n",
    "r_abl = fsb.track.assessTracking(ta_abl)\n",
    "\n",
    "ta_ctrl = np.array(np.hsplit(ta_ctrl, ta_ctrl.shape[1]/750))\n",
    "ta_abl = np.array(np.hsplit(ta_abl, ta_abl.shape[1]/750))\n",
    "\n",
    "# inds_sort_ctrl = np.argsort(r_ctrl)\n",
    "# inds_sort_abl = np.argsort(r_abl)\n",
    "inds_sort_ctrl = np.arange(ta_ctrl.shape[0])\n",
    "inds_sort_abl = np.arange(ta_abl.shape[0])\n",
    "\n",
    "path_ctrl = glob.glob(ctrl.Path.iloc[0] +  '/procData*.h5')[-1]\n",
    "path_abl = glob.glob(abl.Path.iloc[0] +  '/procData*.h5')[-1]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "trl_ctrl = inds_sort_ctrl[iTrl[0]]\n",
    "y_ctrl = ta_ctrl[trl_ctrl][-1]\n",
    "t = (np.arange(len(y_ctrl))-50)*(1/500)*1000\n",
    "plt.plot(t, y_ctrl, label='Ctrl')\n",
    "\n",
    "trl_abl = inds_sort_abl[iTrl[1]]\n",
    "y_abl = ta_abl[trl_abl][-1]\n",
    "plt.plot(t, y_abl, label='Abl')\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xlim(-30, 500)\n",
    "print(trl_abl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_now = path_abl\n",
    "trl_abl = trl_abl\n",
    "\n",
    "dir_imgs_abl = rsp.remove_suffix_from_paths(os.path.split(dir_now)[0])[()]\n",
    "trlInds = np.arange(trl_abl*trlLen, (trl_abl+1)*trlLen)\n",
    "%time imgs_abl_raw = volt.dask_array_from_image_sequence(dir_imgs_abl)[trlInds].compute()\n",
    "\n",
    "print('Prob images...')\n",
    "%time imgs_fish, imgs_prob = fsb.fish_imgs_from_raw(imgs_abl_raw, unet_fsb, batch_size=6)\n",
    "# img_back = fsb.track.computeBackground(dir_imgs_abl)\n",
    "# imgs_fish, imgs_prob = fsb.fish_imgs_from_raw(imgs_abl_raw-img_back, unet_fsb, batch_size=6)\n",
    "\n",
    "\n",
    "print('Tail angles...')\n",
    "%time ml = fsb.track.midlines_from_binary_imgs(imgs_fish)[0]\n",
    "%time ta = fsb.track.curvaturesAlongMidline(ml)\n",
    "ta = np.cumsum(ta, axis=0)\n",
    "ta = hf.cleanTailAngles(ta, svd=svd, nWaves=2, dt=1/500)[0]\n",
    "y = ta[-1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "t = (np.arange(len(y))-50)*(1/500)*1000\n",
    "plt.plot(t, y)\n",
    "plt.xlim(-30, 500)\n",
    "\n",
    "print('Cropping...')\n",
    "out = fsb.track.find_and_crop_imgs_around_fish(-imgs_abl_raw*imgs_fish, cropSize=(150, 150))\n",
    "fishPos, imgs_crop = out['fishPos'], out['imgs_crop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time ml = fsb.track.midlines_from_binary_imgs(imgs_fish)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = (-20, 500)\n",
    "save = False\n",
    "sfx = 'largeSlowCounterBend'\n",
    "\n",
    "t = (np.arange(len(y))-50)*(1/500)*1000\n",
    "inds = np.where((t>=xl[0]) & (t<=xl[1]))[0]\n",
    "\n",
    "savePath = os.path.join(dir_save, f'Movie-{util.timestamp(\"second\")}_{sfx}.avi')\n",
    "%time ani = hf.see_behavior_with_labels(imgs_crop[inds], y[inds], savePath=savePath, save=save)\n",
    "# %time ani = hf.see_behavior_with_labels(imgs_abl_raw[inds], y_abl[inds], savePath=savePath, save=save)\n",
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Additional training, if need be*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRange = (-100, 300)\n",
    "nImgsToCopy=10\n",
    "\n",
    "t = (np.arange(imgs_abl_raw.shape[0])-40)*(1/500)*1000\n",
    "iRange = np.where((t>=tRange[0]) & (t<=tRange[-1]))[0]\n",
    "iRange = (iRange[0], iRange[-1])\n",
    "# inds = np.random.randint(*iRange, nImgsToCopy)\n",
    "inds = np.random.choice(np.arange(*iRange), size=nImgsToCopy, replace=False)\n",
    "dir_imgs_train = os.path.split(dir_now)[0]\n",
    "os.makedirs(dir_imgs_train, exist_ok=True)\n",
    "%time foo = fsb.copy_images_for_training(imgs_abl_raw[inds], savePath=dir_imgs_train, detect_motion_frames=False);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_xls_train = r'Y:\\Avinash\\Ablations and Behavior'\n",
    "file_xls_train = 'Paths_to_fish_training_images.xlsx'\n",
    "sheet_name = 'Uncropped'\n",
    "xls_train = pd.read_excel(os.path.join(dir_xls_train, file_xls_train), sheet_name=sheet_name)\n",
    "xls_train = xls_train.loc[xls_train.exptType=='fsb']\n",
    "\n",
    "imgDims = unet_fsb.input_shape[1:3]\n",
    "imgs_train, masks_train = mlearn.read_training_images_and_masks(np.array(xls_train.pathToImages), \n",
    "                                                    np.array(xls_train.pathToMasks), imgDims=imgDims)\n",
    "masks_train = (masks_train>0).astype(int)\n",
    "print(f'Training on {imgs_train.shape[0]} of dimensions {imgs_train.shape[1:]}')\n",
    "\n",
    "metrics = unet_fsb.evaluate(imgs_train[..., None], masks_train[..., None], batch_size=6, verbose=1)\n",
    "print(np.c_[unet_fsb.metrics_names, metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Check pointer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Checkpointer callback for storing best weights\n",
    "fp = os.path.join(dir_unet, f'best_weights_fsb_{util.timestamp()}.hdf')\n",
    "checkpointer = ModelCheckpoint(filepath=fp, monitor='val_dice_coef', verbose=1,\\\n",
    "                               save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "keras_callbacks = [checkpointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Augmentation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Augment before training\n",
    "upSample=5\n",
    "aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot', 'rs')\n",
    "%time imgs_aug, masks_aug, augs = mlearn.augmentImageData(imgs_train, masks_train,\\\n",
    "                                                          upsample=upSample, aug_set=aug_set)\n",
    "\n",
    "imgs_aug = mlearn.prepare_imgs_for_unet(imgs_aug, unet_fsb)\n",
    "masks_aug = mlearn.prepare_imgs_for_unet(masks_aug, unet_fsb)\n",
    "masks_aug = (masks_aug>0).astype(int)\n",
    "print(f'Augmentation: {len(imgs_train)} --> {len(imgs_aug)}')\n",
    "\n",
    "metrics = unet_fsb.evaluate(imgs_aug, masks_aug, batch_size=6, verbose=1)\n",
    "print(np.c_[unet_fsb.metrics_names, metrics])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Run cell below if a new model is to be instantiated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 'default'\n",
    "\n",
    "if learning_rate is 'default':\n",
    "    print('Default learning rate')\n",
    "#     optimizer = keras.optimizers.rmsprop()\n",
    "    optimizer = keras.optimizers.adam()\n",
    "else:\n",
    "#     optimizer = keras.optimizers.rmsprop(learning_rate=learning_rate)\n",
    "    optimizer = keras.optimizers.adam(learning_rate=learning_rate)\n",
    "    \n",
    "unet_fsb = model.get_unet(img_width=896, img_height=896, img_channels=1, optimizer=optimizer,\n",
    "                          loss=model.focal_loss)\n",
    "file_weights = os.path.join(dir_unet, 'best_weights_fsb_20200404-17.hdf')\n",
    "\n",
    "unet_fsb.load_weights(file_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 6 # For 1024 x 1024 images I can't help but use this size\n",
    "epochs = 150\n",
    "validation_split = 0.1\n",
    "checkPoint = True\n",
    "\n",
    "his = unet_fsb.fit(imgs_aug, masks_aug, epochs=epochs, batch_size=batch_size,\\\n",
    "                   validation_split=validation_split, callbacks=keras_callbacks, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load the best weights from the checkpointed file and save the U net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Load the best weights and save\n",
    "fn = ft.findAndSortFilesInDir(dir_unet, search_str='best_weights_fsb_2020', ext='hdf')[-1]\n",
    "print(fn)\n",
    "unet_fsb.load_weights(os.path.join(dir_unet, fn))\n",
    "\n",
    "#%% Save the U-net\n",
    "# dir_unet = r'Y:\\Avinash\\Ablations and Behavior'\n",
    "fn = f'trainedU_fsb_{unet_fsb.input_shape[1]}x{unet_fsb.input_shape[2]}_{util.timestamp(\"minute\")}.h5'\n",
    "unet_fsb.save(os.path.join(dir_unet, fn))\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = unet_fsb.history.history\n",
    "print(his.keys())\n",
    "plt.style.use(('seaborn-white', 'seaborn-ticks', 'seaborn-talk', 'fivethirtyeight'))\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['val_dice_coef'],'.', label='validation set')\n",
    "plt.plot(his['dice_coef'], label='training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Dice coefficient', fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(his['val_loss'],'.', label ='validation set')\n",
    "plt.plot(his['loss'], label = 'training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Binary cross-entropy loss', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Evaluate metrics again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = unet_fsb.evaluate(imgs_aug, masks_aug, batch_size=6, verbose=1)\n",
    "print(np.c_[unet_fsb.metrics_names, metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Randomly select and plot images and masks for checking* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.permutation(np.arange(imgs_train.shape[0]))\n",
    "ind=inds[0]\n",
    "m = montage((imgs_train[ind], masks_train[ind]), rescale_intensity=True, grid_shape=(1,2))\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(m, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Read a contiguous set of unseen images for predicting with U-net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iFish = 2\n",
    "iTrl = 7\n",
    "trlLen = 750\n",
    "\n",
    "fishInds = np.unique(df.FishIdx)\n",
    "dir_imgs= rsp.remove_suffix_from_paths(df.loc[df.FishIdx==fishInds[iFish]].iloc[0].Path)[()]\n",
    "\n",
    "trlInds = np.arange(iTrl*trlLen, (iTrl+1)*trlLen)\n",
    "%time imgPaths = [os.path.join(dir_imgs, _) for _ in ft.findAndSortFilesInDir(dir_imgs, ext='bmp')[trlInds]]\n",
    "\n",
    "\n",
    "imgs = volt.img.readImagesInDir(imgPaths=imgPaths)\n",
    "imgs_rs = volt.img.resize(imgs, unet_fsb.input_shape[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Generate probability maps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prob = np.squeeze(unet_fsb.predict(imgs_rs[..., None], batch_size=6, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Make a movie to demonstrate segmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "merge_ch = 0\n",
    "fps = 50\n",
    "cropSize = (256, 256)\n",
    "iRange = (20, 300)\n",
    "save=True\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "fp = fsb.track.findFish(-imgs_rs*imgs_prob, back_img=None)\n",
    "fp_interp = spt.interp.nanInterp1d(fp)\n",
    "\n",
    "inds = np.arange(*iRange)\n",
    "imgs_rs_crop = volt.img.cropImgsAroundPoints(imgs_rs[inds], fp_interp[inds], cropSize=cropSize)\n",
    "imgs_prob_crop = volt.img.cropImgsAroundPoints(imgs_prob[inds], fp_interp[inds], cropSize=cropSize)\n",
    "\n",
    "\n",
    "imgs_prob_255 = (imgs_prob_crop*255).astype(int)\n",
    "imgs_rs_rgb = np.array([gray2rgb(_, alpha=0.5) for _ in imgs_rs_crop])\n",
    "\n",
    "imgs_rs_rgb[..., merge_ch] = (alpha*imgs_rs_rgb[..., merge_ch] + (1-alpha)*imgs_prob_255).astype(int) \n",
    "\n",
    "dir_save = os.path.join(dir_imgs, 'proc')\n",
    "if not os.path.exists(dir_save):\n",
    "    os.mkdir(dir_save)\n",
    "fname = f'Tracking movie_trl[{iTrl}]_inTrlFrames[{iRange[0]}-{iRange[1]}]_imgDims[{cropSize[0]}x{cropSize[1]}]_{util.timestamp(\"minute\")}.avi'\n",
    "savePath = os.path.join(dir_save, fname)\n",
    "\n",
    "ani =volt.animate_images(imgs_rs_rgb, fps=fps, fig_size=(15, 15), save=save, savePath=savePath)\n",
    "print(f'Movie saved at\\n{dir_save}\\nas\\n{fname}')\n",
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Copy these images for training if performance not great*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_rs[inds].shape\n",
    "inds_mov = np.arange(37, len(inds))\n",
    "np.random.shuffle(inds_mov)\n",
    "# inds_mov = inds_mov[:10]\n",
    "# savePath = os.path.join(dir_save, 'images_train_896x')\n",
    "foo = fsb.copy_images_for_training(imgs_rs[inds][inds_mov], savePath=dir_save, nImgsToCopy=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsb.copy_images_for_training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *From segmented fish images to tail curvature timeseries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = fsb.fish_imgs_from_raw(imgs_rs, unet)[0]\n",
    "%time midlines, inds_kept_midlines = fsb.track.midlines_from_binary_imgs(imgs_fish)\n",
    "kappas = fsb.track.curvaturesAlongMidline(midlines, n=50)\n",
    "tailAngles = np.cumsum(kappas, axis=0)\n",
    "ta = hf.cleanTailAngles(tailAngles)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Plot tail angles extracted from segmented fish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot tail angles\n",
    "\n",
    "from matplotlib.colors import DivergingNorm\n",
    "norm = DivergingNorm(0, vmin=-100, vmax=100)\n",
    "fh, ax = plt.subplots(2,1, figsize=(20,10), sharex=True)\n",
    "\n",
    "ax[0].imshow(ta[:, inds], aspect='auto', norm=norm, cmap='coolwarm', vmin=-100, vmax=100)\n",
    "ax[0].set_yticks([0, 24, 49])\n",
    "ax[0].set_yticklabels(['Head', 'Middle', 'Tail'])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_title('Cumulative curvature along the tail')\n",
    "\n",
    "ax[1].plot(ta[-1][inds])\n",
    "ax[1].set_xlim(0, len(inds))\n",
    "ax[1].set_xticks([0, len(inds)//2, len(inds)])\n",
    "ax[1].set_xlabel('Image frame #')\n",
    "ax[1].set_ylabel('Tail bend amplitude ($^o$)')\n",
    "ax[1].set_title('Tail tail curvature timeseries');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Try Focal Loss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Instantiate U-net with focal loss specified during compilation\n",
    "unet_fl = model.get_unet(img_width=896, img_height=896, img_channels=1, loss=model.focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Checkpointer callback for storing best weights\n",
    "fp = os.path.join(dir_unet, f'best_weights_headFixed_{util.timestamp()}.hdf')\n",
    "checkpointer = ModelCheckpoint(filepath=fp, monitor='val_dice_coef', verbose=1,\\\n",
    "                               save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "keras_callbacks = [checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Augment before training\n",
    "upSample=4\n",
    "aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot', 'rs')\n",
    "# aug_set=('rn', 'sig', 'log', 'inv', 'heq', 'rot')\n",
    "%time imgs_aug, masks_aug, augs = mlearn.augmentImageData(imgs_train, masks_train,\\\n",
    "                                                          upsample=upSample, aug_set=aug_set)\n",
    "\n",
    "imgs_aug = mlearn.prepare_imgs_for_unet(imgs_aug, unet)\n",
    "masks_aug = mlearn.prepare_imgs_for_unet(masks_aug, unet)\n",
    "print(f'Augmentation: {len(imgs_train)} --> {len(imgs_aug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 6 # For 1024 x 1024 images I can't help but use batch_size=6\n",
    "epochs = 25\n",
    "validation_split = 0.1\n",
    "checkPoint = True\n",
    "\n",
    "his = unet_fl.fit(imgs_aug, masks_aug, epochs=epochs, batch_size=batch_size,\\\n",
    "                   validation_split=validation_split, callbacks=keras_callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = unet_fl.history.history\n",
    "print(his.keys())\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.style.use(('seaborn-poster','fivethirtyeight', 'seaborn-white'))\n",
    "plt.subplot(121)\n",
    "plt.plot(his['val_dice_coef'],'.', label='validation set')\n",
    "plt.plot(his['dice_coef'], label='training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Dice coefficient', fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(his['val_loss'],'.', label ='validation set')\n",
    "plt.plot(his['loss'], label = 'training set')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Foal loss ($\\gamma = 2, unbalanced$)', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prob = np.squeeze(unet_fl.predict(imgs_rs[..., None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "merge_ch = 0\n",
    "fps = 50\n",
    "inds = np.arange(450, 3000)\n",
    "imgs_prob_255 = (imgs_prob*255).astype(int)\n",
    "imgs_rs_rgb = np.array([gray2rgb(_, alpha=0.5) for _ in imgs_rs])\n",
    "\n",
    "imgs_rs_rgb[..., merge_ch] = (alpha*imgs_rs_rgb[..., merge_ch] + (1-alpha)*imgs_prob_255).astype(int) \n",
    "ani =volt.animate_images(imgs_rs_rgb[inds], fps=fps, fig_size=(15, 15))\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time imgs_fish = fsb.fish_imgs_from_raw(imgs_rs, unet_fl)[0]\n",
    "%time midlines, inds_kept_midlines = fsb.track.midlines_from_binary_imgs(imgs_fish)\n",
    "kappas = fsb.track.curvaturesAlongMidline(midlines, n=50)\n",
    "tailAngles = np.cumsum(kappas, axis=0)\n",
    "ta = hf.cleanTailAngles(tailAngles)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot tail angles\n",
    "\n",
    "from matplotlib.colors import DivergingNorm\n",
    "norm = DivergingNorm(0, vmin=-100, vmax=100)\n",
    "fh, ax = plt.subplots(2,1, figsize=(20,10), sharex=True)\n",
    "\n",
    "ax[0].imshow(ta[:, inds], aspect='auto', norm=norm, cmap='coolwarm', vmin=-100, vmax=100)\n",
    "ax[0].set_yticks([0, 24, 49])\n",
    "ax[0].set_yticklabels(['Head', 'Middle', 'Tail'])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_title('Cumulative curvature along the tail')\n",
    "\n",
    "ax[1].plot(ta[-1][inds])\n",
    "ax[1].set_xlim(0, len(inds))\n",
    "ax[1].set_xticks([0, len(inds)//2, len(inds)])\n",
    "ax[1].set_xlabel('Image frame #')\n",
    "ax[1].set_ylabel('Tail bend amplitude ($^o$)')\n",
    "ax[1].set_title('Tail tail curvature timeseries');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Free swim behavior*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
